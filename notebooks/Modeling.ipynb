{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dc4e129",
   "metadata": {},
   "source": [
    "# Predictive Maintenance mit SCANIA-Daten – Modeling\n",
    "\n",
    "**Projekt:** Bachelorarbeit Data Science  \n",
    "**Thema:** \n",
    "**Datengrundlage:** SCANIA Component X Dataset  \n",
    "**Autor:** Justin Stange-Heiduk  \n",
    "**Betreuung:** Dr. Martin Prause  \n",
    "**Ziel:** Modell erstellung XGBoost mit AFT und Random Forest Survival  \n",
    "\n",
    "---\n",
    "\n",
    "**Erstellt:** 2025-09-01  \n",
    "**Letzte Änderung:** 2025-09-25\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eff8099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.util import Surv\n",
    "from sksurv.metrics import concordance_index_censored, integrated_brier_score\n",
    "import mlflow\n",
    "import optuna\n",
    "from optuna.pruners import SuccessiveHalvingPruner\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import time, sys\n",
    "from optuna.samplers import GridSampler\n",
    "from hashlib import sha1\n",
    "import xgboost as xgb\n",
    "import scipy\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9114bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run CommonFunctions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aad7564",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65e9e24",
   "metadata": {},
   "source": [
    "### 1. Random Survival Forest HPO\n",
    "### 2. XGBoost mit AFT HPO\n",
    "### 3. Modellerstellung RSF\n",
    "### 4. Modelerstellung XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad06a607",
   "metadata": {},
   "source": [
    "### 1. Random Survival Forest HPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9d64a5",
   "metadata": {},
   "source": [
    "#### Einlesen der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b0ef421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_rsf_model_input(df: pd.DataFrame, columns_to_drop: list, frag: float, class_column: str, sampling: bool) -> tuple[pd.DataFrame, np.ndarray]: \n",
    "    \"\"\" Prepares the input data for the Random Survival Forest model with option to sample a fraction of each class. \n",
    "    \n",
    "    Args: df (pd.DataFrame): The input dataframe containing features and target variables. \n",
    "    columns_to_drop (list): List of columns to drop from the dataframe. \n",
    "    frag (float): Fraction of data to sample from each class. \n",
    "    class_column (str): The name of the column representing the class labels. \n",
    "    sampling (bool): Whether to perform sampling or not.\n",
    "    Returns: tuple[pd.DataFrame, np.ndarray]: A tuple containing the feature dataframe and the structured array for survival analysis. \"\"\" \n",
    "    df_list = [] \n",
    "\n",
    "    if sampling:\n",
    "        for i in df[class_column].unique(): \n",
    "            df_list.append( df[df[class_column] == i].sample(frac=frag, random_state=42)) \n",
    "        df = pd.concat(df_list) \n",
    "\n",
    "    y_surv = Surv.from_arrays(event=df[\"event\"].astype(bool), time=df[\"duration\"].astype(float)) \n",
    "    X = df.drop(columns=columns_to_drop) \n",
    "    return X, y_surv \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "673bd616",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train_surv = prepare_rsf_model_input(load_df(ordner=\"04_feature\", name = \"feature_train_corr_labels\").drop(columns=[\"upper_bound\"]), columns_to_drop=[\"duration\", \"event\", \"vehicle_id\", \"class\"], frag=0.01, class_column=\"class\", sampling=True) \n",
    "\n",
    "X_val, y_val_surv = prepare_rsf_model_input(load_df(ordner=\"04_feature\", name = \"feature_validation_corr_labels\").drop(columns=[\"upper_bound\"]), columns_to_drop=[\"duration\", \"event\", \"vehicle_id\", \"class_label\"], frag=1.0, class_column=\"class_label\", sampling=False) \n",
    "\n",
    "validation_data = load_df(ordner=\"04_feature\", name = \"feature_validation_corr_labels\").drop(columns=[\"upper_bound\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d6210c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Sicherstellen, dass der Ordner existiert\n",
    "save_dir = \"../Data/05_model_input/HPO_RSF\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# X_train und X_val (DataFrames) speichern\n",
    "X_train.to_parquet(os.path.join(save_dir, \"X_train.parquet\"), index=False)\n",
    "X_val.to_parquet(os.path.join(save_dir, \"X_val.parquet\"), index=False)\n",
    "\n",
    "# y_train_surv und y_val_surv sind Structured Arrays -> DataFrame\n",
    "y_train_df = pd.DataFrame({\n",
    "    \"event\": y_train_surv[\"event\"].astype(int),\n",
    "    \"duration\": y_train_surv[\"time\"].astype(float)\n",
    "})\n",
    "y_val_df = pd.DataFrame({\n",
    "    \"event\": y_val_surv[\"event\"].astype(int),\n",
    "    \"duration\": y_val_surv[\"time\"].astype(float)\n",
    "})\n",
    "\n",
    "y_train_df.to_parquet(os.path.join(save_dir, \"y_train_surv.parquet\"), index=False)\n",
    "y_val_df.to_parquet(os.path.join(save_dir, \"y_val_surv.parquet\"), index=False)\n",
    "\n",
    "# Validation Data auch speichern\n",
    "validation_data.to_parquet(os.path.join(save_dir, \"validation_data.parquet\"), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd45ec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_parquet(\"../Data/05_model_input/HPO_RSF/X_train.parquet\")\n",
    "X_val   = pd.read_parquet(\"../Data/05_model_input/HPO_RSF/X_val.parquet\")\n",
    "y_train_df = pd.read_parquet(\"../Data/05_model_input/HPO_RSF/y_train_surv.parquet\")\n",
    "y_val_df   = pd.read_parquet(\"../Data/05_model_input/HPO_RSF/y_val_surv.parquet\")\n",
    "\n",
    "# Zurück in Surv-Format\n",
    "y_train_surv = Surv.from_arrays(event=y_train_df[\"event\"].astype(bool),\n",
    "                                time=y_train_df[\"duration\"].astype(float))\n",
    "y_val_surv   = Surv.from_arrays(event=y_val_df[\"event\"].astype(bool),\n",
    "                                time=y_val_df[\"duration\"].astype(float))\n",
    "\n",
    "validation_data = pd.read_parquet(\"../Data/05_model_input/HPO_RSF/validation_data.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240b6b91",
   "metadata": {},
   "source": [
    "#### Sichtbare Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "030fd921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(msg):\n",
    "    print(f\"[{time.strftime('%H:%M:%S')}] {msg}\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4db4c2",
   "metadata": {},
   "source": [
    "#### Kostenfunktion und Klassen-Mapping aus der Survivalkurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10ef77b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kostenmatrix aus deinem Paper (Zeilen = Actual n, Spalten = Predicted m)\n",
    "COST = np.array([\n",
    "    [0,   7,   8,   9,   10],\n",
    "    [200, 0,   7,   8,    9],\n",
    "    [300, 200, 0,   7,    8],\n",
    "    [400, 300, 200, 0,    7],\n",
    "    [500, 400, 300, 200,  0]\n",
    "], dtype=float)\n",
    "\n",
    "# Klassengrenzen für RUL in Zeiteinheiten, konsistent zu deinen Labels 0..4\n",
    "# Beispiel: 4: [0,6), 3: [6,12), 2: [12,24), 1: [24,48), 0: [48, inf)\n",
    "TAUS = np.array([6.0, 12.0, 24.0, 48.0], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4b8aee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_probs_from_S_tau(S_tau: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Berechnet p0..p4 direkt aus den Werten S(tau1..tau4).\n",
    "\n",
    "    Args: \n",
    "        S_tau = [S(tau1), S(tau2), S(tau3), S(tau4)].\n",
    "        \n",
    "    Return: Wahrscheinlichkeiten p0..p4 für Klassen 0..4\n",
    "    \"\"\"\n",
    "    S1, S2, S3, S4 = S_tau\n",
    "    p4 = 1.0 - S1\n",
    "    p3 = S1 - S2\n",
    "    p2 = S2 - S3\n",
    "    p1 = S3 - S4\n",
    "    p0 = S4\n",
    "    p = np.clip(np.array([p0, p1, p2, p3, p4], dtype=float), 0.0, 1.0)\n",
    "    s = p.sum()\n",
    "    return p / s if s > 0 else np.array([1.0, 0.0, 0.0, 0.0, 0.0], dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935c5059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_with_cost_from_rsf_at_taus(\n",
    "    rsf: RandomSurvivalForest,\n",
    "    X: pd.DataFrame,\n",
    "    taus: np.ndarray,\n",
    "    cost: np.ndarray\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Ermittelt je Instanz die kostenminimale Klasse m̂ und die dazugehörigen Größen.\n",
    "\n",
    "    Args:\n",
    "        rsf: trainiertes RandomSurvivalForest Modell\n",
    "        X: Eingabedaten (Features) der Form (N, n_features)\n",
    "        taus: Klassengrenzen der Form (4,)\n",
    "        cost: Kostenmatrix der Form (5,5)\n",
    "        \n",
    "    Rückgaben:\n",
    "      pred_class  Länge N\n",
    "      exp_cost_min Länge N\n",
    "      probs       Form (N,5) für p0..p4\n",
    "    \"\"\"\n",
    "    surv_fns = rsf.predict_survival_function(X, return_array=False)\n",
    "    N = len(X)\n",
    "    pred_class = np.zeros(N, dtype=int)\n",
    "    exp_cost_min = np.zeros(N, dtype=float)\n",
    "    probs = np.zeros((N, 5), dtype=float)\n",
    "\n",
    "    for i, fn in enumerate(surv_fns):\n",
    "        S_tau = fn(taus)\n",
    "        p = class_probs_from_S_tau(S_tau)\n",
    "        exp_vec = cost.T @ p\n",
    "        m_hat = int(np.argmin(exp_vec))\n",
    "        pred_class[i] = m_hat\n",
    "        exp_cost_min[i] = float(exp_vec[m_hat])\n",
    "        probs[i, :] = p\n",
    "\n",
    "    return pred_class, exp_cost_min, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d1790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_decision_costs_from_true(\n",
    "    true_class: pd.Series | np.ndarray,\n",
    "    pred_class: np.ndarray,\n",
    "    cost: np.ndarray\n",
    ") -> tuple[float, float, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Berechnet realisierte Kosten Cost[n, m̂] und Konfusion.\n",
    "\n",
    "    Args:\n",
    "        true_class: wahre Klassen der Form (N,)\n",
    "        pred_class: vorhergesagte Klassen der Form (N,)\n",
    "        cost: Kostenmatrix der Form (5,5)\n",
    "        \n",
    "    Rückgaben:\n",
    "      avg_cost, total_cost\n",
    "    \"\"\"\n",
    "    n = np.asarray(true_class, dtype=int)\n",
    "    m = np.asarray(pred_class, dtype=int)\n",
    "    assert n.shape == m.shape, \"true_class und pred_class müssen gleich lang sein.\"\n",
    "\n",
    "    realized = np.array([cost[n_i, m_i] for n_i, m_i in zip(n, m)], dtype=float)\n",
    "    avg_cost = float(np.mean(realized))\n",
    "    total_cost = float(np.sum(realized))\n",
    "\n",
    "\n",
    "\n",
    "    return avg_cost, total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d40c067",
   "metadata": {},
   "source": [
    "#### RSF-Modell und Metriken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52cfa10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_rsf(X: pd.DataFrame, duration: pd.Series, event: pd.Series, **params) -> RandomSurvivalForest:\n",
    "    \"\"\"\n",
    "    Trainiere einen RandomSurvivalForest mit den gegebenen Hyperparametern.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): Die Eingabedaten.\n",
    "        duration (pd.Series): Die Überlebenszeiten.\n",
    "        event (pd.Series): Die Ereignisdaten.\n",
    "        **params: Zusätzliche Hyperparameter für das Modell.\n",
    "\n",
    "    Return:\n",
    "        RandomSurvivalForest: Das trainierte Modell.\n",
    "    \"\"\"\n",
    "    \n",
    "    y = Surv.from_arrays(event=event.astype(bool), time=duration.astype(float))\n",
    "    rsf = RandomSurvivalForest(\n",
    "        n_estimators=params.get(\"n_estimators\"),\n",
    "        max_depth=params.get(\"max_depth\"),\n",
    "        max_features=params.get(\"max_features\"),\n",
    "        min_samples_split=params.get(\"min_samples_split\"),\n",
    "        min_samples_leaf=params.get(\"min_samples_leaf\"),\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    )\n",
    "    log(f\"→ starte FIT mit Parametern: {params}\")\n",
    "    rsf.fit(X, y)\n",
    "    log(\"✓ FIT fertig\")\n",
    "    return rsf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea868843",
   "metadata": {},
   "source": [
    "#### MLflow initialisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d175bddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_mlflow(experiment_name: str, tracking_uri: str | None = None) -> None:\n",
    "    \"\"\"\n",
    "    Setzt MLflow konsistent auf.\n",
    "    - tracking_uri kann sein:\n",
    "      * None           -> nutzt ./mlruns (wird angelegt)\n",
    "      * lokaler Pfad   -> z.B. '/workspace/mlruns' (wird angelegt)\n",
    "      * file-URI       -> z.B. 'file:///workspace/mlruns' (wird angelegt)\n",
    "      * Remote/DB      -> z.B. 'http://...', 'https://...', 'sqlite:///mlflow.db' (kein Ordner nötig)\n",
    "\n",
    "    Args:\n",
    "        experiment_name (str): Name des MLflow-Experiments.\n",
    "        tracking_uri (str | None): URI für das Tracking. Siehe Beschreibung.\n",
    "    \n",
    "    \"\"\"\n",
    "    if tracking_uri is None:\n",
    "        root = Path(\"../mlruns\")\n",
    "        root.mkdir(parents=True, exist_ok=True)\n",
    "        mlflow.set_tracking_uri(root.resolve().as_uri())\n",
    "    else:\n",
    "        parsed = urlparse(tracking_uri)\n",
    "        if parsed.scheme in (\"\", \"file\"):\n",
    "            # Rohpfad oder file-URI -> lokalen Ordner anlegen\n",
    "            root = Path(parsed.path if parsed.scheme == \"file\" else tracking_uri)\n",
    "            root.mkdir(parents=True, exist_ok=True)\n",
    "            mlflow.set_tracking_uri(root.resolve().as_uri())\n",
    "        else:\n",
    "            # http(s), sqlite, postgresql, ...\n",
    "            mlflow.set_tracking_uri(tracking_uri)\n",
    "\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    print(\"MLflow tracking URI:\", mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a2cb39",
   "metadata": {},
   "source": [
    "#### Hyperparameter-Suche mit Optuna und MLflow-Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753c6bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_callback_totalcost(study: optuna.Study, trial: optuna.trial.FrozenTrial):\n",
    "    \"\"\"\n",
    "    Konsolenfeedback pro Trial und Logging der bisherigen Best-Gesamtkosten.\n",
    "\n",
    "    Args:\n",
    "    study (optuna.Study): Die aktuelle Studie.\n",
    "    trial (optuna.trial.FrozenTrial): Der aktuelle Trial.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"[Trial {trial.number:03d}] state={trial.state.name} value={trial.value:.4f} best={study.best_value:.4f}\")\n",
    "        print(\"#\"*20)\n",
    "        mlflow.log_metric(\"best_total_cost_so_far\", study.best_value, step=trial.number)\n",
    "\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c985522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Helper: baut params direkt aus GRID\n",
    "def build_params_from_grid(trial, grid: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Liest alle Keys aus 'grid' und erzeugt passende trial.suggest_categorical()-Aufrufe.\n",
    "    Einzelelement-Listen werden als Konstante gesetzt (keine Suggestion).\n",
    "\n",
    "    Args:\n",
    "        trial (optuna.trial.Trial): Der aktuelle Trial.\n",
    "        grid (dict): Das Hyperparameter-Gitter.\n",
    "    \n",
    "    Return:\n",
    "        dict: Die erzeugten Hyperparameter.\n",
    "    \"\"\"\n",
    "    params = {}\n",
    "    for name, choices in grid.items():\n",
    "        if isinstance(choices, (list, tuple)) and len(choices) > 1:\n",
    "            params[name] = trial.suggest_categorical(name, list(choices))\n",
    "        elif isinstance(choices, (list, tuple)) and len(choices) == 1:\n",
    "            params[name] = choices[0]\n",
    "        else:\n",
    "            # Falls jemand mal einen konstanten Wert statt Liste einträgt\n",
    "            params[name] = choices\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9954493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_params(params: dict) -> str:\n",
    "    return str(sorted(params.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5585ec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsf_objective_prunable_total_cost(\n",
    "    trial: optuna.Trial,\n",
    "    X_tr: pd.DataFrame, y_tr_surv,            # Train für Fit\n",
    "    X_val: pd.DataFrame, y_val_class: pd.Series,  # Val für Entscheidung und echte Klasse\n",
    "    grid: dict,\n",
    "    TRIED_HASHES: set, \n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Mehrstufiges Objective mit Successive Halving.\n",
    "    Ressource = n_estimators. Auswahlkriterium = realisierte Gesamtkosten auf Val.\n",
    "\n",
    "    Args:\n",
    "        trial (optuna.Trial): Der aktuelle Trial.\n",
    "        X_tr (pd.DataFrame): Trainingsdaten für das Fit.\n",
    "        y_tr_surv: Überlebensdaten für das Fit.\n",
    "        X_val (pd.DataFrame): Validierungsdaten für die Entscheidung.\n",
    "        y_val_class (pd.Series): Wahre Klassen für die Kostenberechnung.\n",
    "        grid (dict): Hyperparameter-Gitter.\n",
    "        TRIED_HASHES (set): Menge der bereits getesteten Param-Kombinationen (Hash).\n",
    "    \n",
    "    Return:\n",
    "        float: Die besten realisierten Gesamtkosten auf Val.\n",
    "    \"\"\"\n",
    "\n",
    "    N = len(X_tr)\n",
    "\n",
    "    min_leaf_fracs = [0.005, 0.01, 0.02]\n",
    "    GRID = {\n",
    "    \"max_depth\": [int(np.log2(N)), int(np.log2(N)) + 4],\n",
    "    \"max_features\": [\"sqrt\", 0.4],\n",
    "    \"min_samples_leaf\": [int(N * f) for f in min_leaf_fracs],\n",
    "    \"n_estimators\":      [8, 16, 32, 64]\n",
    "    }\n",
    "    GRID[\"min_samples_split\"] = [2 * v for v in GRID[\"min_samples_leaf\"]]\n",
    "\n",
    "    # Suchraum der Hyperparameter (ohne n_estimators, das ist unsere Stufen-Ressource)\n",
    "    params = {\n",
    "        \"max_depth\":        trial.suggest_categorical(\"max_depth\", [int(np.log2(N)), int(np.log2(N)) + 4]),\n",
    "        \"max_features\":     trial.suggest_categorical(\"max_features\", [\"sqrt\", 0.4]),\n",
    "        \"min_samples_leaf\": trial.suggest_categorical(\"min_samples_leaf\",  [int(N * f) for f in min_leaf_fracs]),\n",
    "    }\n",
    "    params[\"min_samples_split\"] = trial.suggest_categorical(\"min_samples_split\", [2 * v for v in GRID[\"min_samples_leaf\"]])\n",
    "    \n",
    "\n",
    "\n",
    "    # Hash berechnen\n",
    "    params_hash = hash_params(params)\n",
    "\n",
    "    # Trial überspringen, wenn schon getestet\n",
    "    if params_hash in TRIED_HASHES:\n",
    "        print(f\"[SKIP] Trial {trial.number} übersprungen – bekannte Param-Kombi: {params}\")\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    TRIED_HASHES.add(params_hash)\n",
    "\n",
    "\n",
    "    rung_trees = tuple(sorted(grid.get(\"n_estimators\")))\n",
    "\n",
    "    best_full_cost = np.inf\n",
    "    best_n_trees   = None\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.set_tag(\"rungs\", str(rung_trees))\n",
    "        \n",
    "\n",
    "        for step, n_trees in enumerate(rung_trees, start=1): \n",
    "            rsf = fit_rsf(\n",
    "                X_tr,\n",
    "                pd.Series(y_tr_surv[\"time\"],  dtype=float),\n",
    "                pd.Series(y_tr_surv[\"event\"], dtype=bool),\n",
    "                n_estimators=n_trees,\n",
    "                **params\n",
    "            )\n",
    "            # Safety: Feature-Ausrichtung\n",
    "            X_eval = X_val.loc[:, rsf.feature_names_in_] if hasattr(rsf, \"feature_names_in_\") else X_val\n",
    "\n",
    "            # FULL-Entscheidung & realisierte Kosten\n",
    "            pred_full, _, _ = decide_with_cost_from_rsf_at_taus(rsf, X_eval, TAUS, COST)\n",
    "            avg_full, total_full = evaluate_decision_costs_from_true(\n",
    "                true_class=y_val_class, pred_class=pred_full, cost=COST\n",
    "            )\n",
    "\n",
    "            print(f\"[{time.strftime('%H:%M:%S')}] [rung {step}/{len(rung_trees)} FULL] \"\n",
    "                  f\"n_eval={len(X_eval)}  total_cost={total_full:.2f}  avg_cost={avg_full:.4f}\")\n",
    "\n",
    "            # Logging\n",
    "            mlflow.log_metric(\"val_total_cost_full\", total_full, step=step)\n",
    "            mlflow.log_metric(\"val_avg_cost_full\",   avg_full,   step=step)\n",
    "            mlflow.log_metric(\"val_n_eval_full\",     len(X_eval), step=step)\n",
    "            \n",
    "\n",
    "            # Bestes FULL-Ergebnis über die Rungen merken\n",
    "            if total_full < best_full_cost:\n",
    "                best_full_cost = float(total_full)\n",
    "                best_n_trees   = int(n_trees)\n",
    "                best_full_params = dict(params)\n",
    "                best_full_params[\"n_estimators\"] = best_n_trees\n",
    "                trial.set_user_attr(\"best_n_estimators\", best_n_trees)\n",
    "                trial.set_user_attr(\"full_params\", best_full_params)\n",
    "                mlflow.log_metric(\"best_so_far_total_cost_full\", best_full_cost, step=step)\n",
    "                mlflow.set_tag(\"best_so_far_n_estimators\", best_n_trees)\n",
    "\n",
    "            # Pruning basiert ebenfalls auf FULL (du wolltest nur FULL)\n",
    "            if step < len(rung_trees):\n",
    "                trial.report(total_full, step=step)\n",
    "                if trial.should_prune():\n",
    "                    raise optuna.TrialPruned()\n",
    "    \n",
    "        \n",
    "        return float(best_full_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39f864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rsf_study_totalcost(\n",
    "    X_train: pd.DataFrame, y_train_surv,\n",
    "    X_val: pd.DataFrame, y_val_class: pd.Series,\n",
    "    experiment_name: str = \"RSF_HPO_TOTALCOST\",\n",
    "    tracking_uri: str | None = None\n",
    ") -> optuna.Study:\n",
    "    \"\"\"\n",
    "    Startet die Optuna-Studie mit Successive Halving und wählt Hyperparameter\n",
    "    strikt nach minimalen REALISIERTEN Gesamtkosten auf dem Validationset.\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): Trainingsdaten für das Fit.\n",
    "        y_train_surv: Überlebensdaten für das Fit.\n",
    "        X_val (pd.DataFrame): Validierungsdaten für die Entscheidung.\n",
    "        y_val_class (pd.Series): Wahre Klassen für die Kostenberechnung.\n",
    "        experiment_name (str): Name des MLflow-Experiments.\n",
    "        tracking_uri (str | None): URI für das Tracking. Siehe Beschreibung in setup_mlflow().\n",
    "\n",
    "    Return:\n",
    "        optuna.Study: Die durchgeführte Studie.\n",
    "    \"\"\"\n",
    "\n",
    "    TRIED_HASHES = set()\n",
    "\n",
    "    setup_mlflow(experiment_name, tracking_uri)\n",
    "    N = len(X_train)\n",
    "    min_leaf_fracs = [0.005, 0.01, 0.02]\n",
    "    GRID = {\n",
    "    \"max_depth\": [int(np.log2(N)), int(np.log2(N)) + 4],\n",
    "    \"max_features\": [\"sqrt\", 0.4],\n",
    "    \"min_samples_leaf\": [int(N * f) for f in min_leaf_fracs],\n",
    "    \"n_estimators\":      [8, 16, 32, 64]\n",
    "    }\n",
    "    GRID[\"min_samples_split\"] = [2 * v for v in GRID[\"min_samples_leaf\"]]\n",
    "    \n",
    "\n",
    "    n_combos = int(np.prod([len(v) for k, v in GRID.items() if k != \"n_estimators\"]))\n",
    "\n",
    "    sampler = GridSampler(search_space=GRID)\n",
    "    pruner = SuccessiveHalvingPruner(min_resource=1, reduction_factor=10)\n",
    "    study = optuna.create_study(direction=\"minimize\", sampler=sampler, pruner=pruner)\n",
    "\n",
    "    with mlflow.start_run(run_name=\"rsf_hpo_total_cost_sh\"):\n",
    "        study.optimize(\n",
    "            lambda t: rsf_objective_prunable_total_cost(t, X_train, y_train_surv, X_val, y_val_class, grid=GRID, TRIED_HASHES=TRIED_HASHES),\n",
    "            n_trials=n_combos,\n",
    "            show_progress_bar=True,\n",
    "            callbacks=[progress_callback_totalcost],\n",
    "        )\n",
    "        mlflow.log_params(study.best_trial.user_attrs[\"full_params\"])\n",
    "\n",
    "    return study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd90fae",
   "metadata": {},
   "source": [
    "#### Anwendung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d1aba14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 16:54:26,816] A new study created in memory with name: no-name-f03d42f3-ac30-4312-9190-cfc8438e61fd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow tracking URI: file:///workspace/mlruns\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1489e13b79543359d22295abc711546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:54:27] → starte FIT mit Parametern: {'n_estimators': 8, 'max_depth': 13, 'max_features': 'sqrt', 'min_samples_leaf': 56, 'min_samples_split': 224}\n",
      "[16:54:32] ✓ FIT fertig\n",
      "[16:54:32] [rung 1/4 FULL] n_eval=5046  total_cost=52160.00  avg_cost=10.3369\n",
      "[16:54:33] → starte FIT mit Parametern: {'n_estimators': 16, 'max_depth': 13, 'max_features': 'sqrt', 'min_samples_leaf': 56, 'min_samples_split': 224}\n",
      "[W 2025-09-08 16:54:33,457] Trial 0 failed with parameters: {'max_depth': 13, 'max_features': 'sqrt', 'min_samples_leaf': 56, 'min_samples_split': 224} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1089/4179855898.py\", line 34, in <lambda>\n",
      "    lambda t: rsf_objective_prunable_total_cost(t, X_train, y_train_surv, X_val, y_val_class, grid=GRID, TRIED_HASHES=TRIED_HASHES),\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1089/3892130192.py\", line 56, in rsf_objective_prunable_total_cost\n",
      "    rsf = fit_rsf(\n",
      "          ^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1089/480634925.py\", line 27, in fit_rsf\n",
      "    rsf.fit(X, y)\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/sksurv/ensemble/forest.py\", line 184, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=\"threads\")(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\", line 2007, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\", line 1650, in _get_outputs\n",
      "    yield from self._retrieve()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\", line 1762, in _retrieve\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n",
      "[W 2025-09-08 16:54:33,466] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# y_train_surv bereits als structured array vorhanden\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m study \u001b[38;5;241m=\u001b[39m \u001b[43mrun_rsf_study_totalcost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train_surv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train_surv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass_label\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# deine vorhandenen Klassenlabels\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRSF_HPO_TOTALCOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39muser_attrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull_params\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBeste Parameter nach realisierten Gesamtkosten:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_params)\n",
      "Cell \u001b[0;32mIn[19], line 33\u001b[0m, in \u001b[0;36mrun_rsf_study_totalcost\u001b[0;34m(X_train, y_train_surv, X_val, y_val_class, experiment_name, tracking_uri)\u001b[0m\n\u001b[1;32m     30\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m, sampler\u001b[38;5;241m=\u001b[39msampler, pruner\u001b[38;5;241m=\u001b[39mpruner)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run(run_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrsf_hpo_total_cost_sh\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 33\u001b[0m     \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrsf_objective_prunable_total_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_surv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGRID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTRIED_HASHES\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRIED_HASHES\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_combos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprogress_callback_totalcost\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mlog_params(study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39muser_attrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull_params\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m study\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial_id \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py:258\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    254\u001b[0m     updated_state \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    257\u001b[0m ):\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial\u001b[38;5;241m.\u001b[39m_trial_id\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[19], line 34\u001b[0m, in \u001b[0;36mrun_rsf_study_totalcost.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     30\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m, sampler\u001b[38;5;241m=\u001b[39msampler, pruner\u001b[38;5;241m=\u001b[39mpruner)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run(run_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrsf_hpo_total_cost_sh\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     33\u001b[0m     study\u001b[38;5;241m.\u001b[39moptimize(\n\u001b[0;32m---> 34\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mrsf_objective_prunable_total_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_surv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGRID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTRIED_HASHES\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRIED_HASHES\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     35\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_combos,\n\u001b[1;32m     36\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     37\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39m[progress_callback_totalcost],\n\u001b[1;32m     38\u001b[0m     )\n\u001b[1;32m     39\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mlog_params(study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39muser_attrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull_params\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m study\n",
      "Cell \u001b[0;32mIn[18], line 56\u001b[0m, in \u001b[0;36mrsf_objective_prunable_total_cost\u001b[0;34m(trial, X_tr, y_tr_surv, X_val, y_val_class, grid, TRIED_HASHES)\u001b[0m\n\u001b[1;32m     52\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mset_tag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrungs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(rung_trees))\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, n_trees \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(rung_trees, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m): \n\u001b[0;32m---> 56\u001b[0m     rsf \u001b[38;5;241m=\u001b[39m \u001b[43mfit_rsf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_tr_surv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_tr_surv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trees\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# Safety: Feature-Ausrichtung\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     X_eval \u001b[38;5;241m=\u001b[39m X_val\u001b[38;5;241m.\u001b[39mloc[:, rsf\u001b[38;5;241m.\u001b[39mfeature_names_in_] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(rsf, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_names_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m X_val\n",
      "Cell \u001b[0;32mIn[12], line 27\u001b[0m, in \u001b[0;36mfit_rsf\u001b[0;34m(X, duration, event, **params)\u001b[0m\n\u001b[1;32m     16\u001b[0m rsf \u001b[38;5;241m=\u001b[39m RandomSurvivalForest(\n\u001b[1;32m     17\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     18\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     26\u001b[0m log(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m→ starte FIT mit Parametern: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mrsf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m log(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✓ FIT fertig\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rsf\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/sksurv/ensemble/forest.py:184\u001b[0m, in \u001b[0;36m_BaseSurvivalForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    173\u001b[0m y_tree \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    174\u001b[0m     y_numeric,\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munique_times_,\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_event_time_,\n\u001b[1;32m    177\u001b[0m )\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_tree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# y_train_surv bereits als structured array vorhanden\n",
    "study = run_rsf_study_totalcost(\n",
    "    X_train=X_train,\n",
    "    y_train_surv=y_train_surv,\n",
    "    X_val=X_val,\n",
    "    y_val_class=validation_data[\"class_label\"],   # deine vorhandenen Klassenlabels\n",
    "    experiment_name=\"RSF_HPO_TOTALCOST\"\n",
    ")\n",
    "\n",
    "best_params = study.best_trial.user_attrs[\"full_params\"]\n",
    "print(\"Beste Parameter nach realisierten Gesamtkosten:\", best_params)\n",
    "print(\"Beste Gesamtkosten:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ceec74c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(pd.DataFrame([best_params]), ordner=\"05_model_input\", name=\"rsf_best_params_totalcost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6d6a9b",
   "metadata": {},
   "source": [
    "### 2. XGBoosting mit AFT HPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d490e9",
   "metadata": {},
   "source": [
    "#### Daten vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f5d01b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_rsf_model_input(df: pd.DataFrame, columns_to_drop) -> pd.DataFrame: \n",
    "    \"\"\" Prepares the input data for the XGBoost model with aft. \n",
    "    \n",
    "    Args: \n",
    "    df (pd.DataFrame): The input dataframe containing features and target variables. \n",
    "    columns_to_drop (list): List of columns to drop from the dataframe. \n",
    "\n",
    "    Return:\n",
    "    pd.DataFrame: The feature dataframe for XGBoost. \n",
    "    \"\"\"\n",
    "\n",
    "    y = {\n",
    "        \"lower_bound\": df[\"duration\"].astype(float),\n",
    "        \"upper_bound\":  df[\"upper_bound\"].astype(float),\n",
    "    }\n",
    "\n",
    "    x = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    d = xgb.DMatrix(data=x, label_lower_bound=y[\"lower_bound\"],\n",
    "                     label_upper_bound=y[\"upper_bound\"])\n",
    "\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2005e157",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = prepare_rsf_model_input(load_df(ordner=\"04_feature\", name = \"feature_train_corr_labels\"), columns_to_drop=[\"duration\", \"event\", \"vehicle_id\", \"class\", \"upper_bound\"])\n",
    "dval   = prepare_rsf_model_input(load_df(ordner=\"04_feature\", name = \"feature_validation_corr_labels\"), columns_to_drop=[\"duration\", \"event\", \"vehicle_id\", \"class_label\", \"upper_bound\"])\n",
    "labels_val = load_df(ordner=\"04_feature\", name = \"feature_validation_corr_labels\")[\"class_label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa32b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../data/05_model_input\", exist_ok=True)\n",
    "\n",
    "xdtrain.save_binary(\"../data/05_model_input/AFT/xdtrain.buffer\")\n",
    "xdval.save_binary(\"../data/05_model_input/AFT/xdval.buffer\")\n",
    "\n",
    "# Label separat als NumPy/Parquet speichern\n",
    "label_val.to_frame(\"class_label\").to_parquet(\"../data/05_model_input/AFT/label_val.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f72cbc",
   "metadata": {},
   "source": [
    "#### Loss + Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85a0ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_aft_params(trial: optuna.Trial) -> dict:\n",
    "    \"\"\"\n",
    "    Builds hyperparameters for XGBoost AFT model using Optuna trial suggestions.\n",
    "\n",
    "    Args:\n",
    "        trial: optuna.Trial object for hyperparameter suggestions.\n",
    "    \n",
    "    Return:\n",
    "        dict: Hyperparameters for XGBoost AFT model.\n",
    "    \"\"\"\n",
    "    \n",
    "    return {\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"device\": \"cuda\",\n",
    "        \"objective\": \"survival:aft\",\n",
    "        \"aft_loss_distribution\": \"normal\",\n",
    "        \"aft_loss_distribution_scale\": trial.suggest_float(\"aft_loss_distribution_scale\", 0.5, 2.0),\n",
    "        \"eta\": trial.suggest_float(\"eta\", 0.01, 0.3),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1, 50),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-3, 10.0, log=True),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-3, 10.0, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"dart\"]),\n",
    "        \"verbosity\": 0\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8951b5",
   "metadata": {},
   "source": [
    "#### Evaluation über erwartete Kosten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d26adfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_survival_prob(dval: xgb.DMatrix, booster: xgb.Booster, sigma: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Predicts survival probabilities at specified time points using an XGBoost AFT model.\n",
    "\n",
    "    Args:\n",
    "        dval: xgb.DMatrix containing validation data.\n",
    "        booster: Trained XGBoost Booster model.\n",
    "        sigma: Scale parameter for the normal distribution.\n",
    "    \n",
    "    Return:\n",
    "        np.ndarray: Survival probabilities at specified time points.\n",
    "    \"\"\"\n",
    "\n",
    "    mu = booster.predict(dval)  # (n_samples, 2): mean + std\n",
    "    sigma = max(sigma, 1e-3)\n",
    "\n",
    "    # Survivalfunktion S(t) für alle TAUS auswerten\n",
    "    S = np.stack([\n",
    "        1.0 - scipy.stats.norm.cdf(tau, loc=mu, scale=sigma)\n",
    "        for tau in TAUS\n",
    "    ], axis=1)\n",
    "\n",
    "    return S  # shape: (n_samples, len(TAUS))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaed7cd",
   "metadata": {},
   "source": [
    "#### Optuna Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec21cf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aft_objective(trial: optuna.Trial,\n",
    "                  y_val_class: pd.Series,\n",
    "                  dtrain: xgb.DMatrix, dval: xgb.DMatrix,\n",
    "                  experiment_name: str = \"AFT_HPO_TOTALCOST\"\n",
    "                  ) -> float:\n",
    "    \"\"\"\n",
    "    Objective function for Optuna to optimize XGBoost AFT model hyperparameters\n",
    "\n",
    "    Args:\n",
    "        trial: optuna.Trial object for hyperparameter suggestions.\n",
    "        y_val_class: True class labels for validation data.\n",
    "        dtrain: xgb.DMatrix containing training data.\n",
    "        dval: xgb.DMatrix containing validation data.\n",
    "        experiment_name: Name of the MLflow experiment.\n",
    "    \n",
    "    Return:\n",
    "        float: The total expected cost on the validation set.\n",
    "    \"\"\"\n",
    "\n",
    "    params = build_aft_params(trial)\n",
    "\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    with mlflow.start_run(nested=True):\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            evals=[(dtrain, \"train\"), (dval, \"eval\")],\n",
    "            num_boost_round=trial.suggest_int(\"n_estimators\", 50, 1000, step=50),\n",
    "            early_stopping_rounds=50,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "\n",
    "        S_tau = predict_survival_prob(dval, booster, sigma=params[\"aft_loss_distribution_scale\"])\n",
    "        total_cost = total_expected_cost_at_surv(S_tau, TAUS, y_val_class, COST)\n",
    "        mlflow.log_metric(\"val_total_expected_cost\", total_cost)\n",
    "        mlflow.log_metric(\"num_boost_round\", booster.best_iteration)\n",
    "\n",
    "        return total_cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f306199",
   "metadata": {},
   "source": [
    "#### Cost Funktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c438bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_expected_cost_at_surv(S_tau: np.ndarray, taus: np.ndarray,\n",
    "                               true_classes: np.ndarray, cost: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Berechnet die realisierten Gesamtkosten Cost[n, m̂] auf Basis der Über\n",
    "    lebensfunktionen S(tau1..tau4).\n",
    "\n",
    "    Args:\n",
    "        S_tau: Überlebensfunktionen an den Klassengrenzen, Form (N, 4)\n",
    "        taus: Klassengrenzen der Form (4,)\n",
    "        true_classes: Wahre Klassen der Form (N,)\n",
    "        cost: Kostenmatrix der Form (5,5)\n",
    "    \n",
    "    Return:\n",
    "        float: Die realisierten Gesamtkosten.\n",
    "    \"\"\"\n",
    "    total_cost = 0.0\n",
    "    for i, s in enumerate(S_tau):\n",
    "        p = class_probs_from_S_tau(s)\n",
    "        exp_cost = cost.T @ p\n",
    "        m_hat = int(np.argmin(exp_cost))\n",
    "        total_cost += cost[int(true_classes[i]), m_hat]\n",
    "    return total_cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a819f9",
   "metadata": {},
   "source": [
    "#### Anwendung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48f031c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 16:58:22,322] A new study created in memory with name: no-name-d787c649-96f4-4f80-bcda-9be26aa11d0d\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dced2365e1042e7a9cf87e839de8202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/08 16:58:22 INFO mlflow.tracking.fluent: Experiment with name 'AFT_HPO_TOTALCOST' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-09-08 16:58:26,326] Trial 0 failed with parameters: {'aft_loss_distribution_scale': 1.3267901727825773, 'eta': 0.11394375197074692, 'max_depth': 6, 'min_child_weight': 23.340490980843327, 'lambda': 1.1740181831622858, 'alpha': 0.0021045289001949525, 'subsample': 0.68892903206879, 'colsample_bytree': 0.9554128443468315, 'booster': 'dart'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1089/691840537.py\", line 4, in <lambda>\n",
      "    study.optimize(lambda trial: aft_objective(trial, y_val_class=validation_data[\"class_label\"], dtrain=dtrain, dval=dval),\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1089/3933472990.py\", line 11, in aft_objective\n",
      "    mlflow.log_params(params)\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/mlflow/tracking/fluent.py\", line 1167, in log_params\n",
      "    return MlflowClient().log_batch(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/mlflow/tracking/client.py\", line 2378, in log_batch\n",
      "    return self._tracking_client.log_batch(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/mlflow/tracking/_tracking_service/client.py\", line 531, in log_batch\n",
      "    self.store.log_batch(\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/mlflow/store/tracking/file_store.py\", line 1178, in log_batch\n",
      "    self._log_run_param(run_info, param)\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/mlflow/store/tracking/file_store.py\", line 1077, in _log_run_param\n",
      "    param_path = self._get_param_path(run_info.experiment_id, run_info.run_id, param.key)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/mlflow/store/tracking/file_store.py\", line 279, in _get_param_path\n",
      "    self._get_run_dir(experiment_id, run_uuid),\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/mlflow/store/tracking/file_store.py\", line 258, in _get_run_dir\n",
      "    return os.path.join(self._get_experiment_path(experiment_id, assert_exists=True), run_uuid)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/mlflow/store/tracking/file_store.py\", line 244, in _get_experiment_path\n",
      "    exp_list = find(parent, experiment_id, full_path=True)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/mlflow/utils/file_utils.py\", line 191, in find\n",
      "    return list_all(root, lambda x: x == path_name, full_path)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/mlflow/utils/file_utils.py\", line 144, in list_all\n",
      "    matches = [x for x in os.listdir(root) if filter_func(os.path.join(root, x))]\n",
      "                          ^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-09-08 16:58:26,329] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maft_objective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass_label\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m               \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m               \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprogress_callback_totalcost\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m               \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Logge das beste Ergebnis\u001b[39;00m\n\u001b[1;32m     10\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_trial\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial_id \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py:258\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    254\u001b[0m     updated_state \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    257\u001b[0m ):\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial\u001b[38;5;241m.\u001b[39m_trial_id\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[33], line 4\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43maft_objective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass_label\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdval\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      5\u001b[0m                n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m      6\u001b[0m                callbacks\u001b[38;5;241m=\u001b[39m[progress_callback_totalcost],\n\u001b[1;32m      7\u001b[0m                show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Logge das beste Ergebnis\u001b[39;00m\n\u001b[1;32m     10\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_trial\n",
      "Cell \u001b[0;32mIn[31], line 11\u001b[0m, in \u001b[0;36maft_objective\u001b[0;34m(trial, y_val_class, dtrain, dval, experiment_name)\u001b[0m\n\u001b[1;32m      9\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mset_experiment(experiment_name)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run(nested\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     booster \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[1;32m     14\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m     15\u001b[0m         dtrain\u001b[38;5;241m=\u001b[39mdtrain,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m         verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     22\u001b[0m     S_tau \u001b[38;5;241m=\u001b[39m predict_survival_prob(dval, booster, sigma\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maft_loss_distribution_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/mlflow/tracking/fluent.py:1167\u001b[0m, in \u001b[0;36mlog_params\u001b[0;34m(params, synchronous, run_id)\u001b[0m\n\u001b[1;32m   1165\u001b[0m params_arr \u001b[38;5;241m=\u001b[39m [Param(key, \u001b[38;5;28mstr\u001b[39m(value)) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m   1166\u001b[0m synchronous \u001b[38;5;241m=\u001b[39m synchronous \u001b[38;5;28;01mif\u001b[39;00m synchronous \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m MLFLOW_ENABLE_ASYNC_LOGGING\u001b[38;5;241m.\u001b[39mget()\n\u001b[0;32m-> 1167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronous\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/mlflow/tracking/client.py:2378\u001b[0m, in \u001b[0;36mMlflowClient.log_batch\u001b[0;34m(self, run_id, metrics, params, tags, synchronous)\u001b[0m\n\u001b[1;32m   2375\u001b[0m \u001b[38;5;66;03m# Stringify the values of the params\u001b[39;00m\n\u001b[1;32m   2376\u001b[0m params \u001b[38;5;241m=\u001b[39m [Param(key\u001b[38;5;241m=\u001b[39mparam\u001b[38;5;241m.\u001b[39mkey, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(param\u001b[38;5;241m.\u001b[39mvalue)) \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m params]\n\u001b[0;32m-> 2378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronous\u001b[49m\n\u001b[1;32m   2380\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/mlflow/tracking/_tracking_service/client.py:531\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_batch\u001b[0;34m(self, run_id, metrics, params, tags, synchronous)\u001b[0m\n\u001b[1;32m    528\u001b[0m metrics \u001b[38;5;241m=\u001b[39m metrics[metrics_batch_size:]\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synchronous:\n\u001b[0;32m--> 531\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags_batch\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    535\u001b[0m     run_operations_list\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    536\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;241m.\u001b[39mlog_batch_async(\n\u001b[1;32m    537\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mrun_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m         )\n\u001b[1;32m    542\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/mlflow/store/tracking/file_store.py:1178\u001b[0m, in \u001b[0;36mFileStore.log_batch\u001b[0;34m(self, run_id, metrics, params, tags)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1177\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m-> 1178\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_run_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1179\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metrics:\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_run_metric(run_info, metric)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/mlflow/store/tracking/file_store.py:1077\u001b[0m, in \u001b[0;36mFileStore._log_run_param\u001b[0;34m(self, run_info, param)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_log_run_param\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_info, param):\n\u001b[0;32m-> 1077\u001b[0m     param_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_param_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1078\u001b[0m     writeable_param_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writeable_value(param\u001b[38;5;241m.\u001b[39mvalue)\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(param_path):\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/mlflow/store/tracking/file_store.py:279\u001b[0m, in \u001b[0;36mFileStore._get_param_path\u001b[0;34m(self, experiment_id, run_uuid, param_name)\u001b[0m\n\u001b[1;32m    276\u001b[0m _validate_run_id(run_uuid)\n\u001b[1;32m    277\u001b[0m _validate_param_name(param_name)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_run_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_uuid\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    280\u001b[0m     FileStore\u001b[38;5;241m.\u001b[39mPARAMS_FOLDER_NAME,\n\u001b[1;32m    281\u001b[0m     param_name,\n\u001b[1;32m    282\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/mlflow/store/tracking/file_store.py:258\u001b[0m, in \u001b[0;36mFileStore._get_run_dir\u001b[0;34m(self, experiment_id, run_uuid)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_experiment(experiment_id):\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_experiment_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massert_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m, run_uuid)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/mlflow/store/tracking/file_store.py:244\u001b[0m, in \u001b[0;36mFileStore._get_experiment_path\u001b[0;34m(self, experiment_id, view_type, assert_exists)\u001b[0m\n\u001b[1;32m    242\u001b[0m     parents\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrash_folder)\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m parent \u001b[38;5;129;01min\u001b[39;00m parents:\n\u001b[0;32m--> 244\u001b[0m     exp_list \u001b[38;5;241m=\u001b[39m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(exp_list) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    246\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m exp_list[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/mlflow/utils/file_utils.py:191\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(root, name, full_path)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Search for a file in a root directory. Equivalent to:\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m  ``find $root -name \"$name\" -depth 1``\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m    list of matching files or directories.\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    190\u001b[0m path_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, name)\n\u001b[0;32m--> 191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlist_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpath_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/mlflow/utils/file_utils.py:144\u001b[0m, in \u001b[0;36mlist_all\u001b[0;34m(root, filter_func, full_path)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_directory(root):\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid parent directory \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 144\u001b[0m matches \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m filter_func(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, x))]\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m matches] \u001b[38;5;28;01mif\u001b[39;00m full_path \u001b[38;5;28;01melse\u001b[39;00m matches\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "\n",
    "\n",
    "study.optimize(lambda trial: aft_objective(trial, y_val_class=validation_data[\"class_label\"], dtrain=dtrain, dval=dval),\n",
    "               n_trials=1000,\n",
    "               callbacks=[progress_callback_totalcost],\n",
    "               show_progress_bar=True)\n",
    "\n",
    "# Logge das beste Ergebnis\n",
    "best_trial = study.best_trial\n",
    "best_params = best_trial.params\n",
    "mlflow.log_params(best_trial.params)\n",
    "mlflow.log_metric(\"best_val_total_expected_cost\", best_trial.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "540f25c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1571cf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter nach realisierten Gesamtkosten: {'aft_loss_distribution': 'logistic', 'aft_loss_distribution_scale': 0.5, 'learning_rate': 0.28708886146175144, 'max_depth': 14, 'min_child_weight': 96, 'lambda': 0.00028905635749732183, 'alpha': 0.020669977889093343, 'subsample': 0.9859106682012534, 'colsample_bytree': 0.7390509265179644, 'n_estimators': 450}\n"
     ]
    }
   ],
   "source": [
    "print(\"Beste Parameter nach realisierten Gesamtkosten:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "da78b095",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(pd.DataFrame([best_params]), ordner=\"05_model_input\", name=\"atf_best_params_totalcost\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfb0def",
   "metadata": {},
   "source": [
    "### 3. Modellerstellung RSF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb6fd71",
   "metadata": {},
   "source": [
    "#### Daten vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d31c0202",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train_surv = prepare_rsf_model_input(load_df(ordner=\"04_feature\", name = \"feature_train_corr_labels\").drop(columns=[\"upper_bound\"]), columns_to_drop=[\"duration\", \"event\", \"vehicle_id\", \"class\"], frag=1, class_column=\"class\", sampling=True) \n",
    "\n",
    "X_val, y_val_surv = prepare_rsf_model_input(load_df(ordner=\"04_feature\", name = \"feature_validation_corr_labels\").drop(columns=[\"upper_bound\"]), columns_to_drop=[\"duration\", \"event\", \"vehicle_id\", \"class_label\"], frag=1.0, class_column=\"class_label\", sampling=False) \n",
    "\n",
    "validation_data = load_df(ordner=\"04_feature\", name = \"feature_validation_corr_labels\").drop(columns=[\"upper_bound\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a33f1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sicherstellen, dass der Ordner existiert\n",
    "save_dir = \"../Data/05_model_input/RSF\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# X_train und X_val (DataFrames) speichern\n",
    "X_train.to_parquet(os.path.join(save_dir, \"X_train.parquet\"), index=False)\n",
    "X_val.to_parquet(os.path.join(save_dir, \"X_val.parquet\"), index=False)\n",
    "\n",
    "# y_train_surv und y_val_surv sind Structured Arrays -> DataFrame\n",
    "y_train_df = pd.DataFrame({\n",
    "    \"event\": y_train_surv[\"event\"].astype(int),\n",
    "    \"duration\": y_train_surv[\"time\"].astype(float)\n",
    "})\n",
    "y_val_df = pd.DataFrame({\n",
    "    \"event\": y_val_surv[\"event\"].astype(int),\n",
    "    \"duration\": y_val_surv[\"time\"].astype(float)\n",
    "})\n",
    "\n",
    "y_train_df.to_parquet(os.path.join(save_dir, \"y_train_surv.parquet\"), index=False)\n",
    "y_val_df.to_parquet(os.path.join(save_dir, \"y_val_surv.parquet\"), index=False)\n",
    "\n",
    "# Validation Data auch speichern\n",
    "validation_data.to_parquet(os.path.join(save_dir, \"validation_data.parquet\"), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11300f3d",
   "metadata": {},
   "source": [
    "#### Parameter festlegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae9acb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_rsf(df: pd.DataFrame) -> dict:  \n",
    "    \"\"\" \n",
    "    Berechnet die dynamischen Hyperparameter für RandomSurvivalForest basierend auf der Größe des Trainingsdatensatzes. \n",
    "\n",
    "    Args: \n",
    "        df (pd.DataFrame): Der Trainingsdatensatz.\n",
    "\n",
    "    Returns: dict: Ein Dictionary mit den berechneten Hyperparametern.\n",
    "    \"\"\"\n",
    "    N = len(X_train)\n",
    "\n",
    "    # Dynamische Ableitung aus deinem Grid\n",
    "    min_samples_leaf = int(N * 0.01)\n",
    "    min_samples_split = 2 * min_samples_leaf\n",
    "    max_depth = 16\n",
    "\n",
    "    best_params = {\n",
    "        \"n_estimators\": 128,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"max_features\": \"sqrt\",\n",
    "        \"min_samples_leaf\": min_samples_leaf,\n",
    "        \"min_samples_split\": min_samples_split\n",
    "    }\n",
    "\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b84ae997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final_rsf_and_log(\n",
    "    X_train: pd.DataFrame, y_train_surv: Surv,\n",
    "    experiment_name: str = \"RSF_final\", model_name: str = \"Rsf_final_model\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Train and log the final Random Survival Forest model.\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): The training features.\n",
    "        y_train_surv (Surv): The training survival data.\n",
    "        best_params (dict): The best hyperparameters for the model.\n",
    "        experiment_name (str): The name of the MLflow experiment.\n",
    "        model_name (str): The name of the model to register in MLflow.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    best_params = param_rsf(X_train)\n",
    "    with mlflow.start_run(run_name=experiment_name):\n",
    "\n",
    "        mlflow.log_params(best_params)\n",
    "\n",
    "        rsf = RandomSurvivalForest(\n",
    "            n_estimators=best_params[\"n_estimators\"],\n",
    "            max_depth=best_params[\"max_depth\"],\n",
    "            max_features=best_params[\"max_features\"],\n",
    "            min_samples_leaf=best_params[\"min_samples_leaf\"],\n",
    "            min_samples_split=best_params[\"min_samples_split\"],\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        rsf.fit(X_train, y_train_surv)\n",
    "\n",
    "        # MLflow Logging (als sklearn-Modell)\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=rsf,\n",
    "            artifact_path=\"model\",\n",
    "            registered_model_name=model_name\n",
    "        )\n",
    "\n",
    "        print(\"RSF Training abgeschlossen & in MLflow gespeichert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9095e33",
   "metadata": {},
   "source": [
    "#### Anwendung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e2bd54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/08 16:47:47 INFO mlflow.tracking.fluent: Experiment with name 'RSF_final' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_final_rsf_and_log\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_surv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRSF_final\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRsf_final_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 33\u001b[0m, in \u001b[0;36mtrain_final_rsf_and_log\u001b[0;34m(X_train, y_train_surv, experiment_name, model_name)\u001b[0m\n\u001b[1;32m     21\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_params(best_params)\n\u001b[1;32m     23\u001b[0m rsf \u001b[38;5;241m=\u001b[39m RandomSurvivalForest(\n\u001b[1;32m     24\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39mbest_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     25\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39mbest_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     31\u001b[0m )\n\u001b[0;32m---> 33\u001b[0m \u001b[43mrsf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_surv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# MLflow Logging (als sklearn-Modell)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m mlflow\u001b[38;5;241m.\u001b[39msklearn\u001b[38;5;241m.\u001b[39mlog_model(\n\u001b[1;32m     37\u001b[0m     sk_model\u001b[38;5;241m=\u001b[39mrsf,\n\u001b[1;32m     38\u001b[0m     artifact_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     39\u001b[0m     registered_model_name\u001b[38;5;241m=\u001b[39mmodel_name\n\u001b[1;32m     40\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/sksurv/ensemble/forest.py:184\u001b[0m, in \u001b[0;36m_BaseSurvivalForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    173\u001b[0m y_tree \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    174\u001b[0m     y_numeric,\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munique_times_,\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_event_time_,\n\u001b[1;32m    177\u001b[0m )\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_tree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_final_rsf_and_log(X_train, y_train_surv, experiment_name=\"RSF_final\", model_name=\"Rsf_final_model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f88614",
   "metadata": {},
   "source": [
    "### 4. Modellerstellung XGBosst mit AFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59e358a",
   "metadata": {},
   "source": [
    "#### Daten vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "397cb54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdtrain = prepare_rsf_model_input(load_df(ordner=\"04_feature\", name = \"feature_train_corr_labels\"), columns_to_drop=[\"duration\", \"event\", \"vehicle_id\", \"class\", \"upper_bound\"])\n",
    "xdval   = prepare_rsf_model_input(load_df(ordner=\"04_feature\", name = \"feature_validation_corr_labels\"), columns_to_drop=[\"duration\", \"event\", \"vehicle_id\", \"class_label\", \"upper_bound\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b711883",
   "metadata": {},
   "source": [
    "#### Parameter vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90192f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_params_df_aft() -> tuple[dict, int]:\n",
    "    \"\"\"\n",
    "    Liest die besten Parameter aus den HPOs und gibt sie als DataFrame zurück.\n",
    "\n",
    "    return: pd.DataFrame mit den besten Parametern.\n",
    "    \"\"\"\n",
    "\n",
    "    best_params = load_df(ordner=\"05_model_input\", name=\"atf_best_params_totalcost\").iloc[0].to_dict()\n",
    "\n",
    "    params = {\n",
    "        \"tree_method\": \"hist\",             # oder \"gpu_hist\" je nach Version\n",
    "        \"device\": \"cuda\",\n",
    "        \"objective\": \"survival:aft\",\n",
    "        \"aft_loss_distribution\": best_params[\"aft_loss_distribution\"],     # 'logistic'\n",
    "        \"aft_loss_distribution_scale\": float(best_params[\"aft_loss_distribution_scale\"]),\n",
    "        \"eta\": float(best_params[\"learning_rate\"]),\n",
    "        \"max_depth\": int(best_params[\"max_depth\"]),\n",
    "        \"min_child_weight\": int(best_params[\"min_child_weight\"]),\n",
    "        \"reg_lambda\": float(best_params[\"lambda\"]),\n",
    "        \"reg_alpha\": float(best_params[\"alpha\"]),\n",
    "        \"subsample\": float(best_params[\"subsample\"]),\n",
    "        \"colsample_bytree\": float(best_params[\"colsample_bytree\"]),\n",
    "        # booster kannst du weglassen oder explizit auf \"gbtree\" setzen\n",
    "        \"verbosity\": 1\n",
    "    }\n",
    "\n",
    "    num_boost_round = int(best_params[\"n_estimators\"])\n",
    "\n",
    "    return params, num_boost_round\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb83e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fertig. Modell lokal gespeichert unter: data/06_models/XGB_AFT_final_model\n"
     ]
    }
   ],
   "source": [
    "def train_final_aft_and_log(\n",
    "    xdtrain: xgb.DMatrix, xdval: xgb.DMatrix, experiment_name: str = \"XGB_AFT_final\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the final XGBoost AFT model and log the results.\n",
    "\n",
    "    Args:\n",
    "        xdtrain (xgb.DMatrix): The training data for the final model.\n",
    "        xdval (xgb.DMatrix): The validation data for early stopping.\n",
    "        best_params (dict): The best hyperparameters from the Optuna study.\n",
    "        num_boost_round (int): The number of boosting rounds.\n",
    "        experiment_name (str): The name of the MLflow experiment.\n",
    "\n",
    "    Returns:\n",
    "        xgb.Booster: The trained XGBoost Booster model.\n",
    "    \"\"\"\n",
    "    params, num_boost_round = prepare_params_df_aft()\n",
    "    setup_mlflow(experiment_name)\n",
    "    early_stopping_rounds = 50  # Du kannst das anpassen oder entfernen, wenn nicht gewünscht\n",
    "    with mlflow.start_run(run_name=\"XGB_AFT_final\"):\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=xdtrain,\n",
    "            num_boost_round=num_boost_round,\n",
    "            evals=[(xdval, \"val\")],              # für Early Stopping; entferne diese Zeile + early_stopping_rounds, falls unerwünscht\n",
    "            early_stopping_rounds=early_stopping_rounds,\n",
    "            verbose_eval=50\n",
    "        )\n",
    "\n",
    "    # In MLflow loggen (Artefakt)\n",
    "    mlflow.xgboost.log_model(\n",
    "        xgb_model=booster,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=\"AFT_final_model\"  # optional: Modellregistry\n",
    "    )\n",
    "\n",
    "    # Lokal im MLflow-Format speichern\n",
    "    local_path = \"data/06_models/AFT_final_model\"\n",
    "    mlflow.xgboost.save_model(xgb_model=booster, path=local_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cd077c",
   "metadata": {},
   "source": [
    "#### Anwendung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc1d23c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/08 07:48:25 INFO mlflow.tracking.fluent: Experiment with name 'XGB_AFT_final' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow tracking URI: file:///workspace/mlruns\n",
      "[0]\tval-aft-nloglik:0.67713\n",
      "[50]\tval-aft-nloglik:16.08798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/08 07:48:26 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:158: UserWarning: [07:48:27] WARNING: /home/coder/xgboost/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\u001b[31m2025/09/08 07:48:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'AFT_final_model' already exists. Creating a new version of this model...\n",
      "Created version '3' of model 'AFT_final_model'.\n",
      "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:158: UserWarning: [07:48:31] WARNING: /home/coder/xgboost/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_final_aft_and_log(xdtrain, xdval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
