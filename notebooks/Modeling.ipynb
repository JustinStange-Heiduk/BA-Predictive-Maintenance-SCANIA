{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dc4e129",
   "metadata": {},
   "source": [
    "# Predictive Maintenance mit SCANIA-Daten – Modeling\n",
    "\n",
    "**Projekt:** Bachelorarbeit Data Science  \n",
    "**Thema:** \n",
    "**Datengrundlage:** SCANIA Component X Dataset  \n",
    "**Autor:** Justin Stange-Heiduk  \n",
    "**Betreuung:** Dr. Martin Prause  \n",
    "**Ziel:** Modell erstellung XGBoost mit AFT und Random Forest Survival  \n",
    "\n",
    "---\n",
    "\n",
    "**Erstellt:** 2025-09-01  \n",
    "**Letzte Änderung:** 2025-09-25\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eff8099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.util import Surv\n",
    "from sksurv.metrics import concordance_index_censored, integrated_brier_score\n",
    "import mlflow\n",
    "import optuna\n",
    "from optuna.pruners import SuccessiveHalvingPruner\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import time, sys\n",
    "from optuna.samplers import GridSampler\n",
    "from hashlib import sha1\n",
    "import xgboost as xgb\n",
    "import scipy\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9114bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run CommonFunctions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aad7564",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65e9e24",
   "metadata": {},
   "source": [
    "### 1. Random Survival Forest HPO\n",
    "### 2. XGBoost mit AFT HPO\n",
    "### 3. Modellerstellung RSF\n",
    "### 4. Modelerstellung XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9d64a5",
   "metadata": {},
   "source": [
    "#### Einlesen der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b0ef421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_rsf_model_input(df: pd.DataFrame, columns_to_drop: list, frag: float, class_column: str, sampling: bool) -> tuple[pd.DataFrame, np.ndarray]: \n",
    "    \"\"\" Prepares the input data for the Random Survival Forest model with option to sample a fraction of each class. \n",
    "    \n",
    "    Args: df (pd.DataFrame): The input dataframe containing features and target variables. \n",
    "    columns_to_drop (list): List of columns to drop from the dataframe. \n",
    "    frag (float): Fraction of data to sample from each class. \n",
    "    class_column (str): The name of the column representing the class labels. \n",
    "    sampling (bool): Whether to perform sampling or not.\n",
    "    Returns: tuple[pd.DataFrame, np.ndarray]: A tuple containing the feature dataframe and the structured array for survival analysis. \"\"\" \n",
    "    df_list = [] \n",
    "\n",
    "    if sampling:\n",
    "        for i in df[class_column].unique(): \n",
    "            df_list.append( df[df[class_column] == i].sample(frac=frag, random_state=42)) \n",
    "        df = pd.concat(df_list) \n",
    "\n",
    "    y_surv = Surv.from_arrays(event=df[\"event\"].astype(bool), time=df[\"duration\"].astype(float)) \n",
    "    X = df.drop(columns=columns_to_drop) \n",
    "    return X, y_surv \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "673bd616",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train_surv = prepare_rsf_model_input(load_df(ordner=\"04_feature\", name = \"feature_train_corr_labels\").drop(columns=[\"upper_bound\"]), columns_to_drop=[\"duration\", \"event\", \"vehicle_id\", \"class\"], frag=0.01, class_column=\"class\", sampling=True) \n",
    "\n",
    "X_val, y_val_surv = prepare_rsf_model_input(load_df(ordner=\"04_feature\", name = \"feature_validation_corr_labels\").drop(columns=[\"upper_bound\"]), columns_to_drop=[\"duration\", \"event\", \"vehicle_id\", \"class_label\"], frag=1.0, class_column=\"class_label\", sampling=False) \n",
    "\n",
    "validation_data = load_df(ordner=\"04_feature\", name = \"feature_validation_corr_labels\").drop(columns=[\"upper_bound\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d6210c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Sicherstellen, dass der Ordner existiert\n",
    "save_dir = \"../Data/05_model_input/HPO_RSF\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# X_train und X_val (DataFrames) speichern\n",
    "X_train.to_parquet(os.path.join(save_dir, \"X_train.parquet\"), index=False)\n",
    "X_val.to_parquet(os.path.join(save_dir, \"X_val.parquet\"), index=False)\n",
    "\n",
    "# y_train_surv und y_val_surv sind Structured Arrays -> DataFrame\n",
    "y_train_df = pd.DataFrame({\n",
    "    \"event\": y_train_surv[\"event\"].astype(int),\n",
    "    \"duration\": y_train_surv[\"time\"].astype(float)\n",
    "})\n",
    "y_val_df = pd.DataFrame({\n",
    "    \"event\": y_val_surv[\"event\"].astype(int),\n",
    "    \"duration\": y_val_surv[\"time\"].astype(float)\n",
    "})\n",
    "\n",
    "y_train_df.to_parquet(os.path.join(save_dir, \"y_train_surv.parquet\"), index=False)\n",
    "y_val_df.to_parquet(os.path.join(save_dir, \"y_val_surv.parquet\"), index=False)\n",
    "\n",
    "# Validation Data auch speichern\n",
    "validation_data.to_parquet(os.path.join(save_dir, \"validation_data.parquet\"), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd45ec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_parquet(\"../Data/05_model_input/HPO_RSF/X_train.parquet\")\n",
    "X_val   = pd.read_parquet(\"../Data/05_model_input/HPO_RSF/X_val.parquet\")\n",
    "y_train_df = pd.read_parquet(\"../Data/05_model_input/HPO_RSF/y_train_surv.parquet\")\n",
    "y_val_df   = pd.read_parquet(\"../Data/05_model_input/HPO_RSF/y_val_surv.parquet\")\n",
    "\n",
    "# Zurück in Surv-Format\n",
    "y_train_surv = Surv.from_arrays(event=y_train_df[\"event\"].astype(bool),\n",
    "                                time=y_train_df[\"duration\"].astype(float))\n",
    "y_val_surv   = Surv.from_arrays(event=y_val_df[\"event\"].astype(bool),\n",
    "                                time=y_val_df[\"duration\"].astype(float))\n",
    "\n",
    "validation_data = pd.read_parquet(\"../Data/05_model_input/HPO_RSF/validation_data.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94c680a",
   "metadata": {},
   "source": [
    "### 1. Random Survival Forest HPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240b6b91",
   "metadata": {},
   "source": [
    "#### Sichtbare Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "030fd921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(msg):\n",
    "    print(f\"[{time.strftime('%H:%M:%S')}] {msg}\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4db4c2",
   "metadata": {},
   "source": [
    "#### Kostenfunktion und Klassen-Mapping aus der Survivalkurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10ef77b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kostenmatrix aus deinem Paper (Zeilen = Actual n, Spalten = Predicted m)\n",
    "COST = np.array([\n",
    "    [0,   7,   8,   9,   10],\n",
    "    [200, 0,   7,   8,    9],\n",
    "    [300, 200, 0,   7,    8],\n",
    "    [400, 300, 200, 0,    7],\n",
    "    [500, 400, 300, 200,  0]\n",
    "], dtype=float)\n",
    "\n",
    "# Klassengrenzen für RUL in Zeiteinheiten, konsistent zu deinen Labels 0..4\n",
    "# Beispiel: 4: [0,6), 3: [6,12), 2: [12,24), 1: [24,48), 0: [48, inf)\n",
    "TAUS = np.array([6.0, 12.0, 24.0, 48.0], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4b8aee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_probs_from_S_tau(S_tau: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Berechnet p0..p4 direkt aus den Werten S(tau1..tau4).\n",
    "\n",
    "    Args: \n",
    "        S_tau = [S(tau1), S(tau2), S(tau3), S(tau4)].\n",
    "        \n",
    "    Return: Wahrscheinlichkeiten p0..p4 für Klassen 0..4\n",
    "    \"\"\"\n",
    "    S1, S2, S3, S4 = S_tau\n",
    "    p4 = 1.0 - S1\n",
    "    p3 = S1 - S2\n",
    "    p2 = S2 - S3\n",
    "    p1 = S3 - S4\n",
    "    p0 = S4\n",
    "    p = np.clip(np.array([p0, p1, p2, p3, p4], dtype=float), 0.0, 1.0)\n",
    "    s = p.sum()\n",
    "    return p / s if s > 0 else np.array([1.0, 0.0, 0.0, 0.0, 0.0], dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "935c5059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_with_cost_from_rsf_at_taus(\n",
    "    rsf: RandomSurvivalForest,\n",
    "    X: pd.DataFrame,\n",
    "    taus: np.ndarray,\n",
    "    cost: np.ndarray\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Ermittelt je Instanz die kostenminimale Klasse m̂ und die dazugehörigen Größen.\n",
    "    Rückgaben:\n",
    "      pred_class  Länge N\n",
    "      exp_cost_min Länge N\n",
    "      probs       Form (N,5) für p0..p4\n",
    "    \"\"\"\n",
    "    surv_fns = rsf.predict_survival_function(X, return_array=False)\n",
    "    N = len(X)\n",
    "    pred_class = np.zeros(N, dtype=int)\n",
    "    exp_cost_min = np.zeros(N, dtype=float)\n",
    "    probs = np.zeros((N, 5), dtype=float)\n",
    "\n",
    "    for i, fn in enumerate(surv_fns):\n",
    "        S_tau = fn(taus)\n",
    "        p = class_probs_from_S_tau(S_tau)\n",
    "        exp_vec = cost.T @ p\n",
    "        m_hat = int(np.argmin(exp_vec))\n",
    "        pred_class[i] = m_hat\n",
    "        exp_cost_min[i] = float(exp_vec[m_hat])\n",
    "        probs[i, :] = p\n",
    "\n",
    "    return pred_class, exp_cost_min, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7d1790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_decision_costs_from_true(\n",
    "    true_class: pd.Series | np.ndarray,\n",
    "    pred_class: np.ndarray,\n",
    "    cost: np.ndarray\n",
    ") -> tuple[float, float, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Berechnet realisierte Kosten Cost[n, m̂] und Konfusion.\n",
    "    Rückgaben:\n",
    "      avg_cost, total_cost\n",
    "    \"\"\"\n",
    "    n = np.asarray(true_class, dtype=int)\n",
    "    m = np.asarray(pred_class, dtype=int)\n",
    "    assert n.shape == m.shape, \"true_class und pred_class müssen gleich lang sein.\"\n",
    "\n",
    "    realized = np.array([cost[n_i, m_i] for n_i, m_i in zip(n, m)], dtype=float)\n",
    "    avg_cost = float(np.mean(realized))\n",
    "    total_cost = float(np.sum(realized))\n",
    "\n",
    "\n",
    "\n",
    "    return avg_cost, total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d40c067",
   "metadata": {},
   "source": [
    "#### RSF-Modell und Metriken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52cfa10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_rsf(X: pd.DataFrame, duration: pd.Series, event: pd.Series, **params) -> RandomSurvivalForest:\n",
    "    \"\"\"\n",
    "    Trainiere einen RandomSurvivalForest mit den gegebenen Hyperparametern.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): Die Eingabedaten.\n",
    "        duration (pd.Series): Die Überlebenszeiten.\n",
    "        event (pd.Series): Die Ereignisdaten.\n",
    "        **params: Zusätzliche Hyperparameter für das Modell.\n",
    "\n",
    "    Return:\n",
    "        RandomSurvivalForest: Das trainierte Modell.\n",
    "    \"\"\"\n",
    "    \n",
    "    y = Surv.from_arrays(event=event.astype(bool), time=duration.astype(float))\n",
    "    rsf = RandomSurvivalForest(\n",
    "        n_estimators=params.get(\"n_estimators\"),\n",
    "        max_depth=params.get(\"max_depth\"),\n",
    "        max_features=params.get(\"max_features\"),\n",
    "        min_samples_split=params.get(\"min_samples_split\"),\n",
    "        min_samples_leaf=params.get(\"min_samples_leaf\"),\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    )\n",
    "    log(f\"→ starte FIT mit Parametern: {params}\")\n",
    "    rsf.fit(X, y)\n",
    "    log(\"✓ FIT fertig\")\n",
    "    return rsf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea868843",
   "metadata": {},
   "source": [
    "#### MLflow initialisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d175bddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_mlflow(experiment_name: str, tracking_uri: str | None = None) -> None:\n",
    "    \"\"\"\n",
    "    Setzt MLflow konsistent auf.\n",
    "    - tracking_uri kann sein:\n",
    "      * None           -> nutzt ./mlruns (wird angelegt)\n",
    "      * lokaler Pfad   -> z.B. '/workspace/mlruns' (wird angelegt)\n",
    "      * file-URI       -> z.B. 'file:///workspace/mlruns' (wird angelegt)\n",
    "      * Remote/DB      -> z.B. 'http://...', 'https://...', 'sqlite:///mlflow.db' (kein Ordner nötig)\n",
    "    \"\"\"\n",
    "    if tracking_uri is None:\n",
    "        root = Path(\"../mlruns\")\n",
    "        root.mkdir(parents=True, exist_ok=True)\n",
    "        mlflow.set_tracking_uri(root.resolve().as_uri())\n",
    "    else:\n",
    "        parsed = urlparse(tracking_uri)\n",
    "        if parsed.scheme in (\"\", \"file\"):\n",
    "            # Rohpfad oder file-URI -> lokalen Ordner anlegen\n",
    "            root = Path(parsed.path if parsed.scheme == \"file\" else tracking_uri)\n",
    "            root.mkdir(parents=True, exist_ok=True)\n",
    "            mlflow.set_tracking_uri(root.resolve().as_uri())\n",
    "        else:\n",
    "            # http(s), sqlite, postgresql, ...\n",
    "            mlflow.set_tracking_uri(tracking_uri)\n",
    "\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    print(\"MLflow tracking URI:\", mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a2cb39",
   "metadata": {},
   "source": [
    "#### Hyperparameter-Suche mit Optuna und MLflow-Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "753c6bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_callback_totalcost(study: optuna.Study, trial: optuna.trial.FrozenTrial):\n",
    "    \"\"\"\n",
    "    Konsolenfeedback pro Trial und Logging der bisherigen Best-Gesamtkosten.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"[Trial {trial.number:03d}] state={trial.state.name} value={trial.value:.4f} best={study.best_value:.4f}\")\n",
    "        print(\"#\"*20)\n",
    "        mlflow.log_metric(\"best_total_cost_so_far\", study.best_value, step=trial.number)\n",
    "\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c985522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Helper: baut params direkt aus GRID\n",
    "def build_params_from_grid(trial, grid: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Liest alle Keys aus 'grid' und erzeugt passende trial.suggest_categorical()-Aufrufe.\n",
    "    Einzelelement-Listen werden als Konstante gesetzt (keine Suggestion).\n",
    "    \"\"\"\n",
    "    params = {}\n",
    "    for name, choices in grid.items():\n",
    "        if isinstance(choices, (list, tuple)) and len(choices) > 1:\n",
    "            params[name] = trial.suggest_categorical(name, list(choices))\n",
    "        elif isinstance(choices, (list, tuple)) and len(choices) == 1:\n",
    "            params[name] = choices[0]\n",
    "        else:\n",
    "            # Falls jemand mal einen konstanten Wert statt Liste einträgt\n",
    "            params[name] = choices\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9954493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_params(params: dict) -> str:\n",
    "    return str(sorted(params.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5585ec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsf_objective_prunable_total_cost(\n",
    "    trial: optuna.Trial,\n",
    "    X_tr: pd.DataFrame, y_tr_surv,            # Train für Fit\n",
    "    X_val: pd.DataFrame, y_val_class: pd.Series,  # Val für Entscheidung und echte Klasse\n",
    "    grid: dict,\n",
    "    TRIED_HASHES: set, \n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Mehrstufiges Objective mit Successive Halving.\n",
    "    Ressource = n_estimators. Auswahlkriterium = realisierte Gesamtkosten auf Val.\n",
    "    \"\"\"\n",
    "\n",
    "    N = len(X_tr)\n",
    "\n",
    "    min_leaf_fracs = [0.005, 0.01, 0.02]\n",
    "    GRID = {\n",
    "    \"max_depth\": [int(np.log2(N)), int(np.log2(N)) + 4],\n",
    "    \"max_features\": [\"sqrt\", 0.4],\n",
    "    \"min_samples_leaf\": [int(N * f) for f in min_leaf_fracs],\n",
    "    \"n_estimators\":      [8, 16, 32, 64]\n",
    "    }\n",
    "    GRID[\"min_samples_split\"] = [2 * v for v in GRID[\"min_samples_leaf\"]]\n",
    "\n",
    "    # Suchraum der Hyperparameter (ohne n_estimators, das ist unsere Stufen-Ressource)\n",
    "    params = {\n",
    "        \"max_depth\":        trial.suggest_categorical(\"max_depth\", [int(np.log2(N)), int(np.log2(N)) + 4]),\n",
    "        \"max_features\":     trial.suggest_categorical(\"max_features\", [\"sqrt\", 0.4]),\n",
    "        \"min_samples_leaf\": trial.suggest_categorical(\"min_samples_leaf\",  [int(N * f) for f in min_leaf_fracs]),\n",
    "    }\n",
    "    params[\"min_samples_split\"] = trial.suggest_categorical(\"min_samples_split\", [2 * v for v in GRID[\"min_samples_leaf\"]])\n",
    "    \n",
    "\n",
    "\n",
    "    # Hash berechnen\n",
    "    params_hash = hash_params(params)\n",
    "\n",
    "    # Trial überspringen, wenn schon getestet\n",
    "    if params_hash in TRIED_HASHES:\n",
    "        print(f\"[SKIP] Trial {trial.number} übersprungen – bekannte Param-Kombi: {params}\")\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    TRIED_HASHES.add(params_hash)\n",
    "\n",
    "\n",
    "    rung_trees = tuple(sorted(grid.get(\"n_estimators\")))\n",
    "\n",
    "    best_full_cost = np.inf\n",
    "    best_n_trees   = None\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.set_tag(\"rungs\", str(rung_trees))\n",
    "        \n",
    "\n",
    "        for step, n_trees in enumerate(rung_trees, start=1): \n",
    "            rsf = fit_rsf(\n",
    "                X_tr,\n",
    "                pd.Series(y_tr_surv[\"time\"],  dtype=float),\n",
    "                pd.Series(y_tr_surv[\"event\"], dtype=bool),\n",
    "                n_estimators=n_trees,\n",
    "                **params\n",
    "            )\n",
    "            # Safety: Feature-Ausrichtung\n",
    "            X_eval = X_val.loc[:, rsf.feature_names_in_] if hasattr(rsf, \"feature_names_in_\") else X_val\n",
    "\n",
    "            # FULL-Entscheidung & realisierte Kosten\n",
    "            pred_full, _, _ = decide_with_cost_from_rsf_at_taus(rsf, X_eval, TAUS, COST)\n",
    "            avg_full, total_full = evaluate_decision_costs_from_true(\n",
    "                true_class=y_val_class, pred_class=pred_full, cost=COST\n",
    "            )\n",
    "\n",
    "            print(f\"[{time.strftime('%H:%M:%S')}] [rung {step}/{len(rung_trees)} FULL] \"\n",
    "                  f\"n_eval={len(X_eval)}  total_cost={total_full:.2f}  avg_cost={avg_full:.4f}\")\n",
    "\n",
    "            # Logging\n",
    "            mlflow.log_metric(\"val_total_cost_full\", total_full, step=step)\n",
    "            mlflow.log_metric(\"val_avg_cost_full\",   avg_full,   step=step)\n",
    "            mlflow.log_metric(\"val_n_eval_full\",     len(X_eval), step=step)\n",
    "            \n",
    "\n",
    "            # Bestes FULL-Ergebnis über die Rungen merken\n",
    "            if total_full < best_full_cost:\n",
    "                best_full_cost = float(total_full)\n",
    "                best_n_trees   = int(n_trees)\n",
    "                best_full_params = dict(params)\n",
    "                best_full_params[\"n_estimators\"] = best_n_trees\n",
    "                trial.set_user_attr(\"best_n_estimators\", best_n_trees)\n",
    "                trial.set_user_attr(\"full_params\", best_full_params)\n",
    "                mlflow.log_metric(\"best_so_far_total_cost_full\", best_full_cost, step=step)\n",
    "                mlflow.set_tag(\"best_so_far_n_estimators\", best_n_trees)\n",
    "\n",
    "            # Pruning basiert ebenfalls auf FULL (du wolltest nur FULL)\n",
    "            if step < len(rung_trees):\n",
    "                trial.report(total_full, step=step)\n",
    "                if trial.should_prune():\n",
    "                    raise optuna.TrialPruned()\n",
    "    \n",
    "        \n",
    "        return float(best_full_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e39f864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rsf_study_totalcost(\n",
    "    X_train: pd.DataFrame, y_train_surv,\n",
    "    X_val: pd.DataFrame, y_val_class: pd.Series,\n",
    "    experiment_name: str = \"RSF_HPO_TOTALCOST\",\n",
    "    tracking_uri: str | None = None\n",
    ") -> optuna.Study:\n",
    "    \"\"\"\n",
    "    Startet die Optuna-Studie mit Successive Halving und wählt Hyperparameter\n",
    "    strikt nach minimalen REALISIERTEN Gesamtkosten auf dem Validationset.\n",
    "    \"\"\"\n",
    "\n",
    "    TRIED_HASHES = set()\n",
    "\n",
    "    setup_mlflow(experiment_name, tracking_uri)\n",
    "    N = len(X_train)\n",
    "    min_leaf_fracs = [0.005, 0.01, 0.02]\n",
    "    GRID = {\n",
    "    \"max_depth\": [int(np.log2(N)), int(np.log2(N)) + 4],\n",
    "    \"max_features\": [\"sqrt\", 0.4],\n",
    "    \"min_samples_leaf\": [int(N * f) for f in min_leaf_fracs],\n",
    "    \"n_estimators\":      [8, 16, 32, 64]\n",
    "    }\n",
    "    GRID[\"min_samples_split\"] = [2 * v for v in GRID[\"min_samples_leaf\"]]\n",
    "    \n",
    "\n",
    "    n_combos = int(np.prod([len(v) for k, v in GRID.items() if k != \"n_estimators\"]))\n",
    "\n",
    "    sampler = GridSampler(search_space=GRID)\n",
    "    pruner = SuccessiveHalvingPruner(min_resource=1, reduction_factor=10)\n",
    "    study = optuna.create_study(direction=\"minimize\", sampler=sampler, pruner=pruner)\n",
    "\n",
    "    with mlflow.start_run(run_name=\"rsf_hpo_total_cost_sh\"):\n",
    "        study.optimize(\n",
    "            lambda t: rsf_objective_prunable_total_cost(t, X_train, y_train_surv, X_val, y_val_class, grid=GRID, TRIED_HASHES=TRIED_HASHES),\n",
    "            n_trials=n_combos,\n",
    "            show_progress_bar=True,\n",
    "            callbacks=[progress_callback_totalcost],\n",
    "        )\n",
    "        mlflow.log_params(study.best_trial.user_attrs[\"full_params\"])\n",
    "\n",
    "    return study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e210a7",
   "metadata": {},
   "source": [
    "#### Finales Training mit Bestparametern und Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "72d3608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final_rsf_and_log(\n",
    "    X_trval: pd.DataFrame, y_trval_surv: Surv, best_params: dict,\n",
    "    experiment_name: str = \"RSF_Cost_Tuning\", model_name: str = \"rsf_best.pkl\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the final RandomSurvivalForest model and log the results.\n",
    "\n",
    "    Args:\n",
    "        X_trval (pd.DataFrame): The training features for the final model.\n",
    "        y_trval_surv (Surv): The training survival data for the final model.\n",
    "        best_params (dict): The best hyperparameters from the Optuna study.\n",
    "        experiment_name (str): The name of the MLflow experiment.\n",
    "        model_name (str): The name of the model file to save.\n",
    "\n",
    "    Returns:\n",
    "        RandomSurvivalForest: The trained RandomSurvivalForest model.\n",
    "    \"\"\"\n",
    "    setup_mlflow(experiment_name)\n",
    "    with mlflow.start_run(run_name=\"rsf_final_train\"):\n",
    "        mlflow.log_params(best_params)\n",
    "        rsf = fit_rsf(X_trval, pd.Series(y_trval_surv[\"time\"]), pd.Series(y_trval_surv[\"event\"]), **best_params)\n",
    "        # Modell als Artefakt speichern\n",
    "        out_path = Path(\"artifacts\"); out_path.mkdir(exist_ok=True, parents=True)\n",
    "        model_file = out_path / model_name\n",
    "        with open(model_file, \"wb\") as f:\n",
    "            pickle.dump(rsf, f)\n",
    "        mlflow.log_artifact(str(model_file))\n",
    "    return rsf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd90fae",
   "metadata": {},
   "source": [
    "#### Anwendung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d1aba14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 06:38:40,645] A new study created in memory with name: no-name-cb1ceb31-3bf1-4d57-9c4c-0488292800ed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow tracking URI: file:///workspace/mlruns\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281d2c4b60174b338293c0ceae22398e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:38:41] → starte FIT mit Parametern: {'n_estimators': 8, 'max_depth': 13, 'max_features': 'sqrt', 'min_samples_leaf': 56, 'min_samples_split': 224}\n",
      "[06:38:45] ✓ FIT fertig\n",
      "[06:38:46] [rung 1/4 FULL] n_eval=5046  total_cost=52160.00  avg_cost=10.3369\n",
      "[06:38:46] → starte FIT mit Parametern: {'n_estimators': 16, 'max_depth': 13, 'max_features': 'sqrt', 'min_samples_leaf': 56, 'min_samples_split': 224}\n",
      "[06:38:51] ✓ FIT fertig\n",
      "[06:38:53] [rung 2/4 FULL] n_eval=5046  total_cost=51818.00  avg_cost=10.2691\n",
      "[06:38:53] → starte FIT mit Parametern: {'n_estimators': 32, 'max_depth': 13, 'max_features': 'sqrt', 'min_samples_leaf': 56, 'min_samples_split': 224}\n",
      "[06:39:01] ✓ FIT fertig\n",
      "[06:39:03] [rung 3/4 FULL] n_eval=5046  total_cost=50616.00  avg_cost=10.0309\n",
      "[06:39:04] → starte FIT mit Parametern: {'n_estimators': 64, 'max_depth': 13, 'max_features': 'sqrt', 'min_samples_leaf': 56, 'min_samples_split': 224}\n",
      "[06:39:21] ✓ FIT fertig\n",
      "[06:39:23] [rung 4/4 FULL] n_eval=5046  total_cost=49299.00  avg_cost=9.7699\n",
      "[I 2025-09-04 06:39:24,664] Trial 0 finished with value: 49299.0 and parameters: {'max_depth': 13, 'max_features': 'sqrt', 'min_samples_leaf': 56, 'min_samples_split': 224}. Best is trial 0 with value: 49299.0.\n",
      "[Trial 000] state=COMPLETE value=49299.0000 best=49299.0000\n",
      "####################\n",
      "[06:39:25] → starte FIT mit Parametern: {'n_estimators': 8, 'max_depth': 17, 'max_features': 'sqrt', 'min_samples_leaf': 112, 'min_samples_split': 224}\n",
      "[06:39:29] ✓ FIT fertig\n",
      "[06:39:29] [rung 1/4 FULL] n_eval=5046  total_cost=43131.00  avg_cost=8.5476\n",
      "[06:39:29] → starte FIT mit Parametern: {'n_estimators': 16, 'max_depth': 17, 'max_features': 'sqrt', 'min_samples_leaf': 112, 'min_samples_split': 224}\n",
      "[06:39:33] ✓ FIT fertig\n",
      "[06:39:34] [rung 2/4 FULL] n_eval=5046  total_cost=48808.00  avg_cost=9.6726\n",
      "[06:39:35] → starte FIT mit Parametern: {'n_estimators': 32, 'max_depth': 17, 'max_features': 'sqrt', 'min_samples_leaf': 112, 'min_samples_split': 224}\n",
      "[06:39:43] ✓ FIT fertig\n",
      "[06:39:44] [rung 3/4 FULL] n_eval=5046  total_cost=50294.00  avg_cost=9.9671\n",
      "[06:39:45] → starte FIT mit Parametern: {'n_estimators': 64, 'max_depth': 17, 'max_features': 'sqrt', 'min_samples_leaf': 112, 'min_samples_split': 224}\n",
      "[06:39:58] ✓ FIT fertig\n",
      "[06:40:01] [rung 4/4 FULL] n_eval=5046  total_cost=49222.00  avg_cost=9.7547\n",
      "[I 2025-09-04 06:40:02,260] Trial 1 finished with value: 43131.0 and parameters: {'max_depth': 17, 'max_features': 'sqrt', 'min_samples_leaf': 112, 'min_samples_split': 224}. Best is trial 1 with value: 43131.0.\n",
      "[Trial 001] state=COMPLETE value=43131.0000 best=43131.0000\n",
      "####################\n",
      "[06:40:02] → starte FIT mit Parametern: {'n_estimators': 8, 'max_depth': 17, 'max_features': 'sqrt', 'min_samples_leaf': 224, 'min_samples_split': 112}\n",
      "[06:40:05] ✓ FIT fertig\n",
      "[06:40:06] [rung 1/4 FULL] n_eval=5046  total_cost=47176.00  avg_cost=9.3492\n",
      "[I 2025-09-04 06:40:07,212] Trial 2 pruned. \n",
      "[Trial 002] state=PRUNED value=47176.0000 best=43131.0000\n",
      "####################\n",
      "[06:40:07] → starte FIT mit Parametern: {'n_estimators': 8, 'max_depth': 13, 'max_features': 'sqrt', 'min_samples_leaf': 224, 'min_samples_split': 112}\n",
      "[06:40:10] ✓ FIT fertig\n",
      "[06:40:11] [rung 1/4 FULL] n_eval=5046  total_cost=47176.00  avg_cost=9.3492\n",
      "[I 2025-09-04 06:40:12,209] Trial 3 pruned. \n",
      "[Trial 003] state=PRUNED value=47176.0000 best=43131.0000\n",
      "####################\n",
      "[06:40:12] → starte FIT mit Parametern: {'n_estimators': 8, 'max_depth': 17, 'max_features': 0.4, 'min_samples_leaf': 56, 'min_samples_split': 112}\n",
      "[06:40:21] ✓ FIT fertig\n",
      "[06:40:22] [rung 1/4 FULL] n_eval=5046  total_cost=50166.00  avg_cost=9.9417\n",
      "[I 2025-09-04 06:40:23,231] Trial 4 pruned. \n",
      "[Trial 004] state=PRUNED value=50166.0000 best=43131.0000\n",
      "####################\n",
      "[06:40:23] → starte FIT mit Parametern: {'n_estimators': 8, 'max_depth': 17, 'max_features': 0.4, 'min_samples_leaf': 112, 'min_samples_split': 448}\n",
      "[06:40:29] ✓ FIT fertig\n",
      "[06:40:30] [rung 1/4 FULL] n_eval=5046  total_cost=46864.00  avg_cost=9.2874\n",
      "[I 2025-09-04 06:40:31,124] Trial 5 pruned. \n",
      "[Trial 005] state=PRUNED value=46864.0000 best=43131.0000\n",
      "####################\n",
      "[06:40:31] → starte FIT mit Parametern: {'n_estimators': 8, 'max_depth': 13, 'max_features': 0.4, 'min_samples_leaf': 112, 'min_samples_split': 448}\n",
      "[06:40:38] ✓ FIT fertig\n",
      "[06:40:39] [rung 1/4 FULL] n_eval=5046  total_cost=46864.00  avg_cost=9.2874\n",
      "[I 2025-09-04 06:40:40,423] Trial 6 pruned. \n",
      "[Trial 006] state=PRUNED value=46864.0000 best=43131.0000\n",
      "####################\n",
      "[06:40:40] → starte FIT mit Parametern: {'n_estimators': 8, 'max_depth': 13, 'max_features': 'sqrt', 'min_samples_leaf': 112, 'min_samples_split': 448}\n",
      "[06:40:44] ✓ FIT fertig\n",
      "[06:40:45] [rung 1/4 FULL] n_eval=5046  total_cost=50515.00  avg_cost=10.0109\n",
      "[I 2025-09-04 06:40:46,134] Trial 7 pruned. \n",
      "[Trial 007] state=PRUNED value=50515.0000 best=43131.0000\n",
      "####################\n",
      "[SKIP] Trial 8 übersprungen – bekannte Param-Kombi: {'max_depth': 17, 'max_features': 0.4, 'min_samples_leaf': 112, 'min_samples_split': 448}\n",
      "[I 2025-09-04 06:40:46,309] Trial 8 pruned. \n",
      "[06:40:46] → starte FIT mit Parametern: {'n_estimators': 8, 'max_depth': 13, 'max_features': 'sqrt', 'min_samples_leaf': 112, 'min_samples_split': 224}\n",
      "[06:40:50] ✓ FIT fertig\n",
      "[06:40:51] [rung 1/4 FULL] n_eval=5046  total_cost=43288.00  avg_cost=8.5787\n",
      "[I 2025-09-04 06:40:51,994] Trial 9 pruned. \n",
      "[Trial 009] state=PRUNED value=43288.0000 best=43131.0000\n",
      "####################\n",
      "[06:40:52] → starte FIT mit Parametern: {'n_estimators': 8, 'max_depth': 17, 'max_features': 0.4, 'min_samples_leaf': 112, 'min_samples_split': 224}\n",
      "[06:40:57] ✓ FIT fertig\n",
      "[06:40:57] [rung 1/4 FULL] n_eval=5046  total_cost=48311.00  avg_cost=9.5741\n",
      "[I 2025-09-04 06:40:58,761] Trial 10 pruned. \n",
      "[Trial 010] state=PRUNED value=48311.0000 best=43131.0000\n",
      "####################\n",
      "[06:40:59] → starte FIT mit Parametern: {'n_estimators': 8, 'max_depth': 17, 'max_features': 0.4, 'min_samples_leaf': 112, 'min_samples_split': 112}\n",
      "[06:41:06] ✓ FIT fertig\n",
      "[06:41:07] [rung 1/4 FULL] n_eval=5046  total_cost=48311.00  avg_cost=9.5741\n",
      "[I 2025-09-04 06:41:08,157] Trial 11 pruned. \n",
      "[Trial 011] state=PRUNED value=48311.0000 best=43131.0000\n",
      "####################\n",
      "[06:41:08] → starte FIT mit Parametern: {'n_estimators': 8, 'max_depth': 13, 'max_features': 0.4, 'min_samples_leaf': 56, 'min_samples_split': 224}\n",
      "[06:41:17] ✓ FIT fertig\n",
      "[06:41:18] [rung 1/4 FULL] n_eval=5046  total_cost=50688.00  avg_cost=10.0452\n",
      "[I 2025-09-04 06:41:19,360] Trial 12 pruned. \n",
      "[Trial 012] state=PRUNED value=50688.0000 best=43131.0000\n",
      "####################\n",
      "[06:41:19] → starte FIT mit Parametern: {'n_estimators': 8, 'max_depth': 13, 'max_features': 0.4, 'min_samples_leaf': 56, 'min_samples_split': 448}\n",
      "[06:41:28] ✓ FIT fertig\n",
      "[06:41:28] [rung 1/4 FULL] n_eval=5046  total_cost=48113.00  avg_cost=9.5349\n",
      "[I 2025-09-04 06:41:29,861] Trial 13 pruned. \n",
      "[Trial 013] state=PRUNED value=48113.0000 best=43131.0000\n",
      "####################\n",
      "[06:41:30] → starte FIT mit Parametern: {'n_estimators': 8, 'max_depth': 13, 'max_features': 0.4, 'min_samples_leaf': 112, 'min_samples_split': 224}\n",
      "[06:41:37] ✓ FIT fertig\n",
      "[06:41:38] [rung 1/4 FULL] n_eval=5046  total_cost=48311.00  avg_cost=9.5741\n",
      "[I 2025-09-04 06:41:39,460] Trial 14 pruned. \n",
      "[Trial 014] state=PRUNED value=48311.0000 best=43131.0000\n",
      "####################\n",
      "[06:41:40] → starte FIT mit Parametern: {'n_estimators': 8, 'max_depth': 13, 'max_features': 'sqrt', 'min_samples_leaf': 224, 'min_samples_split': 448}\n",
      "[06:41:42] ✓ FIT fertig\n",
      "[06:41:43] [rung 1/4 FULL] n_eval=5046  total_cost=47176.00  avg_cost=9.3492\n",
      "[I 2025-09-04 06:41:44,325] Trial 15 pruned. \n",
      "[Trial 015] state=PRUNED value=47176.0000 best=43131.0000\n",
      "####################\n",
      "[SKIP] Trial 16 übersprungen – bekannte Param-Kombi: {'max_depth': 13, 'max_features': 'sqrt', 'min_samples_leaf': 224, 'min_samples_split': 112}\n",
      "[I 2025-09-04 06:41:44,495] Trial 16 pruned. \n",
      "[06:41:44] → starte FIT mit Parametern: {'n_estimators': 8, 'max_depth': 13, 'max_features': 'sqrt', 'min_samples_leaf': 56, 'min_samples_split': 448}\n",
      "[06:41:49] ✓ FIT fertig\n",
      "[06:41:49] [rung 1/4 FULL] n_eval=5046  total_cost=47041.00  avg_cost=9.3224\n",
      "[I 2025-09-04 06:41:50,382] Trial 17 pruned. \n",
      "[Trial 017] state=PRUNED value=47041.0000 best=43131.0000\n",
      "####################\n",
      "[SKIP] Trial 18 übersprungen – bekannte Param-Kombi: {'max_depth': 17, 'max_features': 0.4, 'min_samples_leaf': 112, 'min_samples_split': 224}\n",
      "[I 2025-09-04 06:41:50,585] Trial 18 pruned. \n",
      "[06:41:50] → starte FIT mit Parametern: {'n_estimators': 8, 'max_depth': 13, 'max_features': 0.4, 'min_samples_leaf': 112, 'min_samples_split': 112}\n",
      "[06:41:56] ✓ FIT fertig\n",
      "[06:41:57] [rung 1/4 FULL] n_eval=5046  total_cost=48311.00  avg_cost=9.5741\n",
      "[I 2025-09-04 06:41:58,321] Trial 19 pruned. \n",
      "[Trial 019] state=PRUNED value=48311.0000 best=43131.0000\n",
      "####################\n",
      "[06:41:58] → starte FIT mit Parametern: {'n_estimators': 8, 'max_depth': 17, 'max_features': 'sqrt', 'min_samples_leaf': 112, 'min_samples_split': 112}\n",
      "[06:42:02] ✓ FIT fertig\n",
      "[06:42:02] [rung 1/4 FULL] n_eval=5046  total_cost=43131.00  avg_cost=8.5476\n",
      "[06:42:03] → starte FIT mit Parametern: {'n_estimators': 16, 'max_depth': 17, 'max_features': 'sqrt', 'min_samples_leaf': 112, 'min_samples_split': 112}\n",
      "[06:42:08] ✓ FIT fertig\n",
      "[06:42:09] [rung 2/4 FULL] n_eval=5046  total_cost=48808.00  avg_cost=9.6726\n",
      "[06:42:09] → starte FIT mit Parametern: {'n_estimators': 32, 'max_depth': 17, 'max_features': 'sqrt', 'min_samples_leaf': 112, 'min_samples_split': 112}\n",
      "[06:42:17] ✓ FIT fertig\n",
      "[06:42:18] [rung 3/4 FULL] n_eval=5046  total_cost=50294.00  avg_cost=9.9671\n",
      "[06:42:19] → starte FIT mit Parametern: {'n_estimators': 64, 'max_depth': 17, 'max_features': 'sqrt', 'min_samples_leaf': 112, 'min_samples_split': 112}\n",
      "[06:42:32] ✓ FIT fertig\n",
      "[06:42:35] [rung 4/4 FULL] n_eval=5046  total_cost=49222.00  avg_cost=9.7547\n",
      "[I 2025-09-04 06:42:35,951] Trial 20 finished with value: 43131.0 and parameters: {'max_depth': 17, 'max_features': 'sqrt', 'min_samples_leaf': 112, 'min_samples_split': 112}. Best is trial 1 with value: 43131.0.\n",
      "[Trial 020] state=COMPLETE value=43131.0000 best=43131.0000\n",
      "####################\n",
      "[06:42:36] → starte FIT mit Parametern: {'n_estimators': 8, 'max_depth': 17, 'max_features': 0.4, 'min_samples_leaf': 56, 'min_samples_split': 448}\n",
      "[06:42:45] ✓ FIT fertig\n",
      "[06:42:45] [rung 1/4 FULL] n_eval=5046  total_cost=47980.00  avg_cost=9.5085\n",
      "[I 2025-09-04 06:42:46,599] Trial 21 pruned. \n",
      "[Trial 021] state=PRUNED value=47980.0000 best=43131.0000\n",
      "####################\n",
      "[06:42:47] → starte FIT mit Parametern: {'n_estimators': 8, 'max_depth': 13, 'max_features': 0.4, 'min_samples_leaf': 56, 'min_samples_split': 112}\n",
      "[06:42:54] ✓ FIT fertig\n",
      "[06:42:55] [rung 1/4 FULL] n_eval=5046  total_cost=47355.00  avg_cost=9.3847\n",
      "[I 2025-09-04 06:42:56,145] Trial 22 pruned. \n",
      "[Trial 022] state=PRUNED value=47355.0000 best=43131.0000\n",
      "####################\n",
      "[SKIP] Trial 23 übersprungen – bekannte Param-Kombi: {'max_depth': 17, 'max_features': 'sqrt', 'min_samples_leaf': 224, 'min_samples_split': 112}\n",
      "[I 2025-09-04 06:42:56,314] Trial 23 pruned. \n",
      "[SKIP] Trial 24 übersprungen – bekannte Param-Kombi: {'max_depth': 13, 'max_features': 0.4, 'min_samples_leaf': 56, 'min_samples_split': 224}\n",
      "[I 2025-09-04 06:42:56,316] Trial 24 pruned. \n",
      "[06:42:56] → starte FIT mit Parametern: {'n_estimators': 8, 'max_depth': 17, 'max_features': 0.4, 'min_samples_leaf': 56, 'min_samples_split': 224}\n",
      "[06:43:05] ✓ FIT fertig\n",
      "[06:43:06] [rung 1/4 FULL] n_eval=5046  total_cost=50642.00  avg_cost=10.0361\n",
      "[I 2025-09-04 06:43:07,066] Trial 25 pruned. \n",
      "[Trial 025] state=PRUNED value=50642.0000 best=43131.0000\n",
      "####################\n",
      "[06:43:07] → starte FIT mit Parametern: {'n_estimators': 8, 'max_depth': 13, 'max_features': 0.4, 'min_samples_leaf': 224, 'min_samples_split': 112}\n",
      "[06:43:13] ✓ FIT fertig\n",
      "[06:43:14] [rung 1/4 FULL] n_eval=5046  total_cost=48284.00  avg_cost=9.5688\n",
      "[I 2025-09-04 06:43:14,887] Trial 26 pruned. \n",
      "[Trial 026] state=PRUNED value=48284.0000 best=43131.0000\n",
      "####################\n",
      "[06:43:15] → starte FIT mit Parametern: {'n_estimators': 8, 'max_depth': 17, 'max_features': 0.4, 'min_samples_leaf': 224, 'min_samples_split': 448}\n",
      "[06:43:18] ✓ FIT fertig\n",
      "[06:43:19] [rung 1/4 FULL] n_eval=5046  total_cost=48284.00  avg_cost=9.5688\n",
      "[I 2025-09-04 06:43:20,231] Trial 27 pruned. \n",
      "[Trial 027] state=PRUNED value=48284.0000 best=43131.0000\n",
      "####################\n",
      "[06:43:20] → starte FIT mit Parametern: {'n_estimators': 8, 'max_depth': 17, 'max_features': 'sqrt', 'min_samples_leaf': 224, 'min_samples_split': 224}\n",
      "[06:43:23] ✓ FIT fertig\n",
      "[06:43:24] [rung 1/4 FULL] n_eval=5046  total_cost=47176.00  avg_cost=9.3492\n",
      "[I 2025-09-04 06:43:25,341] Trial 28 pruned. \n",
      "[Trial 028] state=PRUNED value=47176.0000 best=43131.0000\n",
      "####################\n",
      "[SKIP] Trial 29 übersprungen – bekannte Param-Kombi: {'max_depth': 13, 'max_features': 'sqrt', 'min_samples_leaf': 112, 'min_samples_split': 224}\n",
      "[I 2025-09-04 06:43:25,504] Trial 29 pruned. \n",
      "[06:43:25] → starte FIT mit Parametern: {'n_estimators': 8, 'max_depth': 13, 'max_features': 0.4, 'min_samples_leaf': 224, 'min_samples_split': 448}\n",
      "[06:43:31] ✓ FIT fertig\n",
      "[06:43:32] [rung 1/4 FULL] n_eval=5046  total_cost=48284.00  avg_cost=9.5688\n",
      "[I 2025-09-04 06:43:33,468] Trial 30 pruned. \n",
      "[Trial 030] state=PRUNED value=48284.0000 best=43131.0000\n",
      "####################\n",
      "[SKIP] Trial 31 übersprungen – bekannte Param-Kombi: {'max_depth': 13, 'max_features': 'sqrt', 'min_samples_leaf': 224, 'min_samples_split': 112}\n",
      "[I 2025-09-04 06:43:33,651] Trial 31 pruned. \n",
      "[SKIP] Trial 32 übersprungen – bekannte Param-Kombi: {'max_depth': 17, 'max_features': 0.4, 'min_samples_leaf': 224, 'min_samples_split': 448}\n",
      "[I 2025-09-04 06:43:33,653] Trial 32 pruned. \n",
      "[06:43:34] → starte FIT mit Parametern: {'n_estimators': 8, 'max_depth': 13, 'max_features': 'sqrt', 'min_samples_leaf': 56, 'min_samples_split': 112}\n",
      "[06:43:38] ✓ FIT fertig\n",
      "[06:43:39] [rung 1/4 FULL] n_eval=5046  total_cost=51658.00  avg_cost=10.2374\n",
      "[I 2025-09-04 06:43:39,971] Trial 33 pruned. \n",
      "[Trial 033] state=PRUNED value=51658.0000 best=43131.0000\n",
      "####################\n",
      "[SKIP] Trial 34 übersprungen – bekannte Param-Kombi: {'max_depth': 13, 'max_features': 0.4, 'min_samples_leaf': 224, 'min_samples_split': 112}\n",
      "[I 2025-09-04 06:43:40,145] Trial 34 pruned. \n",
      "[SKIP] Trial 35 übersprungen – bekannte Param-Kombi: {'max_depth': 13, 'max_features': 'sqrt', 'min_samples_leaf': 56, 'min_samples_split': 448}\n",
      "[I 2025-09-04 06:43:40,147] Trial 35 pruned. \n",
      "Beste Parameter nach realisierten Gesamtkosten: {'max_depth': 17, 'max_features': 'sqrt', 'min_samples_leaf': 112, 'min_samples_split': 224, 'n_estimators': 8}\n",
      "Beste Gesamtkosten: 43131.0\n"
     ]
    }
   ],
   "source": [
    "# y_train_surv bereits als structured array vorhanden\n",
    "study = run_rsf_study_totalcost(\n",
    "    X_train=X_train,\n",
    "    y_train_surv=y_train_surv,\n",
    "    X_val=X_val,\n",
    "    y_val_class=validation_data[\"class_label\"],   # deine vorhandenen Klassenlabels\n",
    "    experiment_name=\"RSF_HPO_TOTALCOST\"\n",
    ")\n",
    "\n",
    "best_params = study.best_trial.user_attrs[\"full_params\"]\n",
    "print(\"Beste Parameter nach realisierten Gesamtkosten:\", best_params)\n",
    "print(\"Beste Gesamtkosten:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ceec74c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(pd.DataFrame([best_params]), ordner=\"05_model_input\", name=\"rsf_best_params_totalcost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6d6a9b",
   "metadata": {},
   "source": [
    "### 2. XGBoosting mit AFT HPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d490e9",
   "metadata": {},
   "source": [
    "#### Daten vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f5d01b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_rsf_model_input(df: pd.DataFrame, columns_to_drop) -> pd.DataFrame: \n",
    "    \"\"\" Prepares the input data for the XGBoost model with aft. \n",
    "    \n",
    "    Args: \n",
    "    df (pd.DataFrame): The input dataframe containing features and target variables. \n",
    "    columns_to_drop (list): List of columns to drop from the dataframe. \n",
    "\n",
    "    Return:\n",
    "    pd.DataFrame: The feature dataframe for XGBoost. \n",
    "    \"\"\"\n",
    "\n",
    "    y = {\n",
    "        \"lower_bound\": df[\"duration\"].astype(float),\n",
    "        \"upper_bound\":  df[\"upper_bound\"].astype(float),\n",
    "    }\n",
    "\n",
    "    x = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    d = xgb.DMatrix(data=x, label_lower_bound=y[\"lower_bound\"],\n",
    "                     label_upper_bound=y[\"upper_bound\"])\n",
    "\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2005e157",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = prepare_rsf_model_input(load_df(ordner=\"04_feature\", name = \"feature_train_corr_labels\"), columns_to_drop=[\"duration\", \"event\", \"vehicle_id\", \"class\", \"upper_bound\"])\n",
    "dval   = prepare_rsf_model_input(load_df(ordner=\"04_feature\", name = \"feature_validation_corr_labels\"), columns_to_drop=[\"duration\", \"event\", \"vehicle_id\", \"class_label\", \"upper_bound\"])\n",
    "labels_val = load_df(ordner=\"04_feature\", name = \"feature_validation_corr_labels\")[\"class_label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa32b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../data/05_model_input\", exist_ok=True)\n",
    "\n",
    "xdtrain.save_binary(\"../data/05_model_input/AFT/xdtrain.buffer\")\n",
    "xdval.save_binary(\"../data/05_model_input/AFT/xdval.buffer\")\n",
    "\n",
    "# Label separat als NumPy/Parquet speichern\n",
    "label_val.to_frame(\"class_label\").to_parquet(\"../data/05_model_input/AFT/label_val.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f72cbc",
   "metadata": {},
   "source": [
    "#### Loss + Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c85a0ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_aft_params(trial: optuna.Trial) -> dict:\n",
    "    return {\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"device\": \"cuda\",\n",
    "        \"objective\": \"survival:aft\",\n",
    "        \"aft_loss_distribution\": \"normal\",\n",
    "        \"aft_loss_distribution_scale\": trial.suggest_float(\"aft_loss_distribution_scale\", 0.5, 2.0),\n",
    "        \"eta\": trial.suggest_float(\"eta\", 0.01, 0.3),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1, 50),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-3, 10.0, log=True),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-3, 10.0, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"dart\"]),\n",
    "        \"verbosity\": 0\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8951b5",
   "metadata": {},
   "source": [
    "#### Evaluation über erwartete Kosten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d26adfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_survival_prob(dval: xgb.DMatrix, booster: xgb.Booster, sigma: float) -> np.ndarray:\n",
    "    mu = booster.predict(dval)  # (n_samples, 2): mean + std\n",
    "    sigma = max(sigma, 1e-3)\n",
    "\n",
    "    # Survivalfunktion S(t) für alle TAUS auswerten\n",
    "    S = np.stack([\n",
    "        1.0 - scipy.stats.norm.cdf(tau, loc=mu, scale=sigma)\n",
    "        for tau in TAUS\n",
    "    ], axis=1)\n",
    "\n",
    "    return S  # shape: (n_samples, len(TAUS))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaed7cd",
   "metadata": {},
   "source": [
    "#### Optuna Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec21cf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aft_objective(trial: optuna.Trial,\n",
    "                  y_val_class: pd.Series,\n",
    "                  dtrain: xgb.DMatrix, dval: xgb.DMatrix\n",
    "                  ) -> float:\n",
    "\n",
    "    params = build_aft_params(trial)\n",
    "\n",
    "    \n",
    "    with mlflow.start_run(nested=True):\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            evals=[(dtrain, \"train\"), (dval, \"eval\")],\n",
    "            num_boost_round=trial.suggest_int(\"n_estimators\", 50, 1000, step=50),\n",
    "            early_stopping_rounds=50,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "\n",
    "        S_tau = predict_survival_prob(dval, booster, sigma=params[\"aft_loss_distribution_scale\"])\n",
    "        total_cost = total_expected_cost_at_surv(S_tau, TAUS, y_val_class, COST)\n",
    "        mlflow.log_metric(\"val_total_expected_cost\", total_cost)\n",
    "        mlflow.log_metric(\"num_boost_round\", booster.best_iteration)\n",
    "\n",
    "        return total_cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f306199",
   "metadata": {},
   "source": [
    "#### Cost Funktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c438bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_expected_cost_at_surv(S_tau: np.ndarray, taus: np.ndarray,\n",
    "                               true_classes: np.ndarray, cost: np.ndarray) -> float:\n",
    "    total_cost = 0.0\n",
    "    for i, s in enumerate(S_tau):\n",
    "        p = class_probs_from_S_tau(s)\n",
    "        exp_cost = cost.T @ p\n",
    "        m_hat = int(np.argmin(exp_cost))\n",
    "        total_cost += cost[int(true_classes[i]), m_hat]\n",
    "    return total_cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a819f9",
   "metadata": {},
   "source": [
    "#### Anwendung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48f031c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 07:40:24,122] A new study created in memory with name: no-name-4bb07b5b-f77b-4e8d-aad6-836aa43849a4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2318f6e3b34240d091636e0a7c3ccd72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-09-08 07:40:24,203] Trial 0 failed with parameters: {'aft_loss_distribution_scale': 1.938020287930645, 'eta': 0.08852303489892008, 'max_depth': 6, 'min_child_weight': 13.498496112311686, 'lambda': 3.5514991119621855, 'alpha': 0.001783294608300569, 'subsample': 0.8310880476691367, 'colsample_bytree': 0.5689057034183203, 'booster': 'dart'} because of the following error: MlflowException('Could not find experiment with ID 0').\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1282/691840537.py\", line 4, in <lambda>\n",
      "    study.optimize(lambda trial: aft_objective(trial, y_val_class=validation_data[\"class_label\"], dtrain=dtrain, dval=dval),\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1282/1070268166.py\", line 9, in aft_objective\n",
      "    with mlflow.start_run(nested=True):\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/mlflow/tracking/fluent.py\", line 474, in start_run\n",
      "    active_run_obj = client.create_run(\n",
      "                     ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/mlflow/tracking/client.py\", line 435, in create_run\n",
      "    return self._tracking_client.create_run(experiment_id, start_time, tags, run_name)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/mlflow/tracking/_tracking_service/client.py\", line 161, in create_run\n",
      "    return self.store.create_run(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/mlflow/store/tracking/file_store.py\", line 671, in create_run\n",
      "    experiment = self.get_experiment(experiment_id)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/mlflow/store/tracking/file_store.py\", line 480, in get_experiment\n",
      "    experiment = self._get_experiment(experiment_id)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/mlflow/store/tracking/file_store.py\", line 450, in _get_experiment\n",
      "    raise MlflowException(\n",
      "mlflow.exceptions.MlflowException: Could not find experiment with ID 0\n",
      "[W 2025-09-08 07:40:24,210] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Could not find experiment with ID 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maft_objective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass_label\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m               \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m               \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprogress_callback_totalcost\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m               \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Logge das beste Ergebnis\u001b[39;00m\n\u001b[1;32m     10\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_trial\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial_id \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py:258\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    254\u001b[0m     updated_state \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    257\u001b[0m ):\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial\u001b[38;5;241m.\u001b[39m_trial_id\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43maft_objective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass_label\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdval\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      5\u001b[0m                n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m      6\u001b[0m                callbacks\u001b[38;5;241m=\u001b[39m[progress_callback_totalcost],\n\u001b[1;32m      7\u001b[0m                show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Logge das beste Ergebnis\u001b[39;00m\n\u001b[1;32m     10\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_trial\n",
      "Cell \u001b[0;32mIn[18], line 9\u001b[0m, in \u001b[0;36maft_objective\u001b[0;34m(trial, y_val_class, dtrain, dval)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21maft_objective\u001b[39m(trial: optuna\u001b[38;5;241m.\u001b[39mTrial,\n\u001b[1;32m      2\u001b[0m                   y_val_class: pd\u001b[38;5;241m.\u001b[39mSeries,\n\u001b[1;32m      3\u001b[0m                   dtrain: xgb\u001b[38;5;241m.\u001b[39mDMatrix, dval: xgb\u001b[38;5;241m.\u001b[39mDMatrix\n\u001b[1;32m      4\u001b[0m                   ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m      6\u001b[0m     params \u001b[38;5;241m=\u001b[39m build_aft_params(trial)\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m:\n\u001b[1;32m     10\u001b[0m         mlflow\u001b[38;5;241m.\u001b[39mlog_params(params)\n\u001b[1;32m     12\u001b[0m         booster \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[1;32m     13\u001b[0m             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m     14\u001b[0m             dtrain\u001b[38;5;241m=\u001b[39mdtrain,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m             verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     19\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/mlflow/tracking/fluent.py:474\u001b[0m, in \u001b[0;36mstart_run\u001b[0;34m(run_id, experiment_id, run_name, nested, parent_run_id, tags, description, log_system_metrics)\u001b[0m\n\u001b[1;32m    470\u001b[0m         user_specified_tags[MLFLOW_RUN_NAME] \u001b[38;5;241m=\u001b[39m run_name\n\u001b[1;32m    472\u001b[0m     resolved_tags \u001b[38;5;241m=\u001b[39m context_registry\u001b[38;5;241m.\u001b[39mresolve_tags(user_specified_tags)\n\u001b[0;32m--> 474\u001b[0m     active_run_obj \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp_id_for_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m log_system_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;66;03m# If `log_system_metrics` is not specified, we will check environment variable.\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     log_system_metrics \u001b[38;5;241m=\u001b[39m MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING\u001b[38;5;241m.\u001b[39mget()\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/mlflow/tracking/client.py:435\u001b[0m, in \u001b[0;36mMlflowClient.create_run\u001b[0;34m(self, experiment_id, start_time, tags, run_name)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_run\u001b[39m(\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    383\u001b[0m     experiment_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    386\u001b[0m     run_name: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    387\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Run:\n\u001b[1;32m    388\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;124;03m    Create a :py:class:`mlflow.entities.Run` object that can be associated with\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;124;03m    metrics, parameters, artifacts, etc.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03m        status: RUNNING\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/mlflow/tracking/_tracking_service/client.py:161\u001b[0m, in \u001b[0;36mTrackingServiceClient.create_run\u001b[0;34m(self, experiment_id, start_time, tags, run_name)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# Extract user from tags\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# This logic is temporary; the user_id attribute of runs is deprecated and will be removed\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# in a later release.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m user_id \u001b[38;5;241m=\u001b[39m tags\u001b[38;5;241m.\u001b[39mget(MLFLOW_USER, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mget_current_time_millis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mRunTag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/mlflow/store/tracking/file_store.py:671\u001b[0m, in \u001b[0;36mFileStore.create_run\u001b[0;34m(self, experiment_id, user_id, start_time, tags, run_name)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;124;03mCreates a run with the specified attributes.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    670\u001b[0m experiment_id \u001b[38;5;241m=\u001b[39m FileStore\u001b[38;5;241m.\u001b[39mDEFAULT_EXPERIMENT_ID \u001b[38;5;28;01mif\u001b[39;00m experiment_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m experiment_id\n\u001b[0;32m--> 671\u001b[0m experiment \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m experiment \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    674\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not create run under experiment with ID \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - no such \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    675\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment exists.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    676\u001b[0m         databricks_pb2\u001b[38;5;241m.\u001b[39mRESOURCE_DOES_NOT_EXIST,\n\u001b[1;32m    677\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/mlflow/store/tracking/file_store.py:480\u001b[0m, in \u001b[0;36mFileStore.get_experiment\u001b[0;34m(self, experiment_id)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;124;03mFetch the experiment.\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03mNote: This API will search for active as well as deleted experiments.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;124;03m    A single Experiment object if it exists, otherwise raises an Exception.\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    479\u001b[0m experiment_id \u001b[38;5;241m=\u001b[39m FileStore\u001b[38;5;241m.\u001b[39mDEFAULT_EXPERIMENT_ID \u001b[38;5;28;01mif\u001b[39;00m experiment_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m experiment_id\n\u001b[0;32m--> 480\u001b[0m experiment \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m experiment \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    483\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExperiment \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    484\u001b[0m         databricks_pb2\u001b[38;5;241m.\u001b[39mRESOURCE_DOES_NOT_EXIST,\n\u001b[1;32m    485\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/mlflow/store/tracking/file_store.py:450\u001b[0m, in \u001b[0;36mFileStore._get_experiment\u001b[0;34m(self, experiment_id, view_type)\u001b[0m\n\u001b[1;32m    448\u001b[0m experiment_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_experiment_path(experiment_id, view_type)\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m experiment_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    451\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find experiment with ID \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    452\u001b[0m         databricks_pb2\u001b[38;5;241m.\u001b[39mRESOURCE_DOES_NOT_EXIST,\n\u001b[1;32m    453\u001b[0m     )\n\u001b[1;32m    454\u001b[0m meta \u001b[38;5;241m=\u001b[39m FileStore\u001b[38;5;241m.\u001b[39m_read_yaml(experiment_dir, FileStore\u001b[38;5;241m.\u001b[39mMETA_DATA_FILE_NAME)\n\u001b[1;32m    455\u001b[0m meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_all_experiment_tags(experiment_id)\n",
      "\u001b[0;31mMlflowException\u001b[0m: Could not find experiment with ID 0"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "\n",
    "\n",
    "study.optimize(lambda trial: aft_objective(trial, y_val_class=validation_data[\"class_label\"], dtrain=dtrain, dval=dval),\n",
    "               n_trials=1000,\n",
    "               callbacks=[progress_callback_totalcost],\n",
    "               show_progress_bar=True)\n",
    "\n",
    "# Logge das beste Ergebnis\n",
    "best_trial = study.best_trial\n",
    "best_params = best_trial.params\n",
    "mlflow.log_params(best_trial.params)\n",
    "mlflow.log_metric(\"best_val_total_expected_cost\", best_trial.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "540f25c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1571cf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter nach realisierten Gesamtkosten: {'aft_loss_distribution': 'logistic', 'aft_loss_distribution_scale': 0.5, 'learning_rate': 0.28708886146175144, 'max_depth': 14, 'min_child_weight': 96, 'lambda': 0.00028905635749732183, 'alpha': 0.020669977889093343, 'subsample': 0.9859106682012534, 'colsample_bytree': 0.7390509265179644, 'n_estimators': 450}\n"
     ]
    }
   ],
   "source": [
    "print(\"Beste Parameter nach realisierten Gesamtkosten:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "da78b095",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(pd.DataFrame([best_params]), ordner=\"05_model_input\", name=\"atf_best_params_totalcost\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfb0def",
   "metadata": {},
   "source": [
    "### 3. Modellerstellung RSF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb6fd71",
   "metadata": {},
   "source": [
    "#### Daten vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31c0202",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train_surv = prepare_rsf_model_input(load_df(ordner=\"04_feature\", name = \"feature_train_corr_labels\").drop(columns=[\"upper_bound\"]), columns_to_drop=[\"duration\", \"event\", \"vehicle_id\", \"class\"], frag=1, class_column=\"class\", sampling=True) \n",
    "\n",
    "X_val, y_val_surv = prepare_rsf_model_input(load_df(ordner=\"04_feature\", name = \"feature_validation_corr_labels\").drop(columns=[\"upper_bound\"]), columns_to_drop=[\"duration\", \"event\", \"vehicle_id\", \"class_label\"], frag=1.0, class_column=\"class_label\", sampling=False) \n",
    "\n",
    "validation_data = load_df(ordner=\"04_feature\", name = \"feature_validation_corr_labels\").drop(columns=[\"upper_bound\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a33f1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sicherstellen, dass der Ordner existiert\n",
    "save_dir = \"../Data/05_model_input/RSF\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# X_train und X_val (DataFrames) speichern\n",
    "X_train.to_parquet(os.path.join(save_dir, \"X_train.parquet\"), index=False)\n",
    "X_val.to_parquet(os.path.join(save_dir, \"X_val.parquet\"), index=False)\n",
    "\n",
    "# y_train_surv und y_val_surv sind Structured Arrays -> DataFrame\n",
    "y_train_df = pd.DataFrame({\n",
    "    \"event\": y_train_surv[\"event\"].astype(int),\n",
    "    \"duration\": y_train_surv[\"time\"].astype(float)\n",
    "})\n",
    "y_val_df = pd.DataFrame({\n",
    "    \"event\": y_val_surv[\"event\"].astype(int),\n",
    "    \"duration\": y_val_surv[\"time\"].astype(float)\n",
    "})\n",
    "\n",
    "y_train_df.to_parquet(os.path.join(save_dir, \"y_train_surv.parquet\"), index=False)\n",
    "y_val_df.to_parquet(os.path.join(save_dir, \"y_val_surv.parquet\"), index=False)\n",
    "\n",
    "# Validation Data auch speichern\n",
    "validation_data.to_parquet(os.path.join(save_dir, \"validation_data.parquet\"), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f88614",
   "metadata": {},
   "source": [
    "### 4. Modellerstellung XGBosst mit AFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59e358a",
   "metadata": {},
   "source": [
    "#### Daten vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "397cb54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdtrain = prepare_rsf_model_input(load_df(ordner=\"04_feature\", name = \"feature_train_corr_labels\"), columns_to_drop=[\"duration\", \"event\", \"vehicle_id\", \"class\", \"upper_bound\"])\n",
    "xdval   = prepare_rsf_model_input(load_df(ordner=\"04_feature\", name = \"feature_validation_corr_labels\"), columns_to_drop=[\"duration\", \"event\", \"vehicle_id\", \"class_label\", \"upper_bound\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b711883",
   "metadata": {},
   "source": [
    "#### Parameter vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f90192f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_params_df() -> tuple[dict, int]:\n",
    "    \"\"\"\n",
    "    Liest die besten Parameter aus den HPOs und gibt sie als DataFrame zurück.\n",
    "\n",
    "    return: pd.DataFrame mit den besten Parametern.\n",
    "    \"\"\"\n",
    "\n",
    "    best_params = load_df(ordner=\"05_model_input\", name=\"atf_best_params_totalcost\").iloc[0].to_dict()\n",
    "\n",
    "    params = {\n",
    "        \"tree_method\": \"hist\",             # oder \"gpu_hist\" je nach Version\n",
    "        \"device\": \"cuda\",\n",
    "        \"objective\": \"survival:aft\",\n",
    "        \"aft_loss_distribution\": best_params[\"aft_loss_distribution\"],     # 'logistic'\n",
    "        \"aft_loss_distribution_scale\": float(best_params[\"aft_loss_distribution_scale\"]),\n",
    "        \"eta\": float(best_params[\"learning_rate\"]),\n",
    "        \"max_depth\": int(best_params[\"max_depth\"]),\n",
    "        \"min_child_weight\": int(best_params[\"min_child_weight\"]),\n",
    "        \"reg_lambda\": float(best_params[\"lambda\"]),\n",
    "        \"reg_alpha\": float(best_params[\"alpha\"]),\n",
    "        \"subsample\": float(best_params[\"subsample\"]),\n",
    "        \"colsample_bytree\": float(best_params[\"colsample_bytree\"]),\n",
    "        # booster kannst du weglassen oder explizit auf \"gbtree\" setzen\n",
    "        \"verbosity\": 1\n",
    "    }\n",
    "\n",
    "    num_boost_round = int(best_params[\"n_estimators\"])\n",
    "\n",
    "    return params, num_boost_round\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb83e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fertig. Modell lokal gespeichert unter: data/06_models/XGB_AFT_final_model\n"
     ]
    }
   ],
   "source": [
    "def train_final_aft_and_log(\n",
    "    xdtrain: xgb.DMatrix, xdval: xgb.DMatrix, experiment_name: str = \"XGB_AFT_final\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the final XGBoost AFT model and log the results.\n",
    "\n",
    "    Args:\n",
    "        xdtrain (xgb.DMatrix): The training data for the final model.\n",
    "        xdval (xgb.DMatrix): The validation data for early stopping.\n",
    "        best_params (dict): The best hyperparameters from the Optuna study.\n",
    "        num_boost_round (int): The number of boosting rounds.\n",
    "        experiment_name (str): The name of the MLflow experiment.\n",
    "\n",
    "    Returns:\n",
    "        xgb.Booster: The trained XGBoost Booster model.\n",
    "    \"\"\"\n",
    "    params, num_boost_round =prepare_params_df()\n",
    "    setup_mlflow(experiment_name)\n",
    "    early_stopping_rounds = 50  # Du kannst das anpassen oder entfernen, wenn nicht gewünscht\n",
    "    with mlflow.start_run(run_name=\"XGB_AFT_final\"):\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=xdtrain,\n",
    "            num_boost_round=num_boost_round,\n",
    "            evals=[(xdval, \"val\")],              # für Early Stopping; entferne diese Zeile + early_stopping_rounds, falls unerwünscht\n",
    "            early_stopping_rounds=early_stopping_rounds,\n",
    "            verbose_eval=50\n",
    "        )\n",
    "\n",
    "    # In MLflow loggen (Artefakt)\n",
    "    mlflow.xgboost.log_model(\n",
    "        xgb_model=booster,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=\"AFT_final_model\"  # optional: Modellregistry\n",
    "    )\n",
    "\n",
    "    # Lokal im MLflow-Format speichern\n",
    "    local_path = \"data/06_models/AFT_final_model\"\n",
    "    mlflow.xgboost.save_model(xgb_model=booster, path=local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc1d23c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/08 07:48:25 INFO mlflow.tracking.fluent: Experiment with name 'XGB_AFT_final' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow tracking URI: file:///workspace/mlruns\n",
      "[0]\tval-aft-nloglik:0.67713\n",
      "[50]\tval-aft-nloglik:16.08798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/08 07:48:26 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:158: UserWarning: [07:48:27] WARNING: /home/coder/xgboost/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\u001b[31m2025/09/08 07:48:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'AFT_final_model' already exists. Creating a new version of this model...\n",
      "Created version '3' of model 'AFT_final_model'.\n",
      "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:158: UserWarning: [07:48:31] WARNING: /home/coder/xgboost/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_final_aft_and_log(xdtrain, xdval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
